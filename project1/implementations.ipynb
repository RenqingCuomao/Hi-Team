{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "604ea1b3-0c3e-490e-9cef-ccd0f0fd1d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "297ecf4f-4c43-48e4-bb81-2a958a2e0f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def batch_iter(y, tx, batch_size, num_batches=1, shuffle=True):\n",
    "    \"\"\"\n",
    "    Generate a minibatch iterator for a dataset.\n",
    "    Takes as input two iterables (here the output desired values 'y' and the input data 'tx')\n",
    "    Outputs an iterator which gives mini-batches of `batch_size` matching elements from `y` and `tx`.\n",
    "    Data can be randomly shuffled to avoid ordering in the original data messing with the randomness of the minibatches.\n",
    "\n",
    "    Example:\n",
    "\n",
    "     Number of batches = 9\n",
    "\n",
    "     Batch size = 7                              Remainder = 3\n",
    "     v     v                                         v v\n",
    "    |-------|-------|-------|-------|-------|-------|---|\n",
    "        0       7       14      21      28      35   max batches = 6\n",
    "\n",
    "    If shuffle is False, the returned batches are the ones started from the indexes:\n",
    "    0, 7, 14, 21, 28, 35, 0, 7, 14\n",
    "\n",
    "    If shuffle is True, the returned batches start in:\n",
    "    7, 28, 14, 35, 14, 0, 21, 28, 7\n",
    "\n",
    "    To prevent the remainder datapoints from ever being taken into account, each of the shuffled indexes is added a random amount\n",
    "    8, 28, 16, 38, 14, 0, 22, 28, 9\n",
    "\n",
    "    This way batches might overlap, but the returned batches are slightly more representative.\n",
    "\n",
    "    Disclaimer: To keep this function simple, individual datapoints are not shuffled. For a more random result consider using a batch_size of 1.\n",
    "\n",
    "    Example of use :\n",
    "    for minibatch_y, minibatch_tx in batch_iter(y, tx, 32):\n",
    "        <DO-SOMETHING>\n",
    "    \"\"\"\n",
    "    data_size = len(y)  # NUmber of data points.\n",
    "    batch_size = min(data_size, batch_size)  # Limit the possible size of the batch.\n",
    "    max_batches = int(\n",
    "        data_size / batch_size\n",
    "    )  # The maximum amount of non-overlapping batches that can be extracted from the data.\n",
    "    remainder = (\n",
    "        data_size - max_batches * batch_size\n",
    "    )  # Points that would be excluded if no overlap is allowed.\n",
    "\n",
    "    if shuffle:\n",
    "        # Generate an array of indexes indicating the start of each batch\n",
    "        idxs = np.random.randint(max_batches, size=num_batches) * batch_size\n",
    "        if remainder != 0:\n",
    "            # Add an random offset to the start of each batch to eventually consider the remainder points\n",
    "            idxs += np.random.randint(remainder + 1, size=num_batches)\n",
    "    else:\n",
    "        # If no shuffle is done, the array of indexes is circular.\n",
    "        idxs = np.array([i % max_batches for i in range(num_batches)]) * batch_size\n",
    "\n",
    "    for start in idxs:\n",
    "        start_index = start  # The first data point of the batch\n",
    "        end_index = (\n",
    "            start_index + batch_size\n",
    "        )  # The first data point of the following batch\n",
    "        yield y[start_index:end_index], tx[start_index:end_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59217bdf-ba9d-4e07-bce6-228a082460a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hessian(y, tx, w):\n",
    "    _sum = np.zeros((w.shape[0], w.shape[0]))\n",
    "    for i in range(y.shape[0]):\n",
    "        _sum = _sum + sigmoid(tx[i, :].dot(w))*(1 - sigmoid(tx[i, :].dot(w)))*tx[i, :].reshape(-1, 1).dot(tx[i, :].reshape(1, -1))\n",
    "    return _sum/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0054b7f-ddda-4b2f-925e-dc020b117bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    return 1/(1 + np.exp(-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f8e6fc-58bf-41e9-a5e0-4136e85354ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lr_gradient(y, tx, w):\n",
    "    return (tx.T.dot(sigmoid(tx.dot(w)) - y))/(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b80f5ee-2aeb-4a1f-9c58-bb6f9a9e5591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lr_loss(y, tx, w):\n",
    "    assert y.shape[0] == tx.shape[0]\n",
    "    assert tx.shape[1] == w.shape[0]\n",
    "    y_star = sigmoid(tx.dot(w))\n",
    "    _sum = 0\n",
    "    for i in range(y.shape[0]):\n",
    "        _sum += (y[i] * math.log(y_star[i]) + (1 - y[i]) * np.log(1 - y_star[i]))\n",
    "    return - _sum[0]/(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be70205d-ab3b-4781-9ee6-544b6d1c6856",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_mse(y, tx, w):\n",
    "    e = y - tx.dot(w)\n",
    "    return (e.T.dot(e))/(2*y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d67feff1-52b1-4d17-9ac0-28308bc7c656",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_mae(y, tx, w):\n",
    "    sum = 0\n",
    "    for i in range(y.shape[0]):\n",
    "        if y[i] - tx[i, :].dot(w) >= 0:\n",
    "            sum += y[i] - tx[i, :].dot(w)\n",
    "        \n",
    "        else:\n",
    "            sum += tx[i, :].dot(w) - y[i]\n",
    "    return sum/(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a92afb2-e018-4b6c-95fe-d986b412880c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_gradient_mse(y, tx, w):\n",
    "    e = y - tx.dot(w)\n",
    "    return -tx.dot(e)/(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52a03e63-0e13-4498-a92a-fb258f49c12b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mse_gd(y, tx, initial_w, max_iters, gamma):\n",
    "    w = initial_w\n",
    "    \n",
    "    for n_iter in range(max_iters):\n",
    "        gradient = compute_gradient_mse(y, tx, w)\n",
    "        w = w - gamma*gradient\n",
    "        loss = compute_mse(y, tx, w)\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade60e13-a103-41b6-a001-785fc9bca878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_sgd(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        #get minibatch\n",
    "        for minibatch_y, minibatch_tx in batch_iter(y, tx, batch_size):\n",
    "            stochastic_grad = compute_gradient_mse(minibatch_y, minibatch_tx, w)\n",
    "            w = w - gamma * stochastic_grad\n",
    "            loss= compute_loss(y,tx,w)\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e01518-504e-4e75-a893-6483cfb302e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(y, tx):\n",
    "    w = np.linalg.solve(tx.T.dot(tx), tx.T.dot(y))\n",
    "    e = y-tx.dot(w)\n",
    "    mse = e.T.dot(e)/(2*y.shape[0])\n",
    "    return w, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441b46f9-76d4-42cc-b557-77d19648ab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    i = np.identity(tx.shape[1])\n",
    "    a = tx.T.dot(tx)+2*y.shape[0]*lambda_*i\n",
    "    b = tx.T.dot(y)\n",
    "    w = np.linalg.solve(a, b)\n",
    "    return w, compute_mse(y, tx, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c736c07f-c624-4223-8e0a-e70a7203d25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_gd(y, tx, initial_w, max_iters, gamma, reg = False):\n",
    "    #if reg is set True, penalty will be applied, which means 'Regularized'\n",
    "    w = initial_w\n",
    "    for i in range(max_iters):\n",
    "        gradient = compute_lr_gradient(y, tx, w)\n",
    "        \n",
    "        if reg:\n",
    "            gradient = gradient + 2*lambda_*w\n",
    "            \n",
    "        w = w - gamma*gradient\n",
    "        loss = compute_lr_loss(y, tx, w)\n",
    "    return w, loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
