{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 4\u001b[0m height, weight, gender \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m(sub_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, add_outlier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m x, mean_x, std_x \u001b[38;5;241m=\u001b[39m standardize(height)\n\u001b[1;32m      6\u001b[0m y, tx \u001b[38;5;241m=\u001b[39m build_model_data(x, weight)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_data' is not defined"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241m.\u001b[39mshape, tx\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the Cost Function\n",
    "Fill in the `compute_loss` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute loss by MSE\n",
    "    # ***************************************************\n",
    "    e = y - tx.dot(w)\n",
    "    \n",
    "    mse = np.mean(e**2)/2\n",
    "\n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w = np.array([[1],[2]])\n",
    "MSE = compute_loss(y, tx, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2721.4427907570757"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from costs import *\n",
    "\n",
    "\n",
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "\n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute loss for each combination of w0 and w1.\n",
    "    # ***************************************************\n",
    "    \n",
    "    \n",
    "    # print(losses)\n",
    "    wi = 0\n",
    "    for w0 in grid_w0:\n",
    "        wj = 0\n",
    "        for w1 in grid_w1:\n",
    "            \n",
    "            w = np.array([w0, w1])\n",
    "            mse = compute_loss(y, tx, w)\n",
    "            losses[wi, wj] = mse\n",
    "            # print(mse)\n",
    "            wj += 1\n",
    "            # print(wj)\n",
    "        wi += 1\n",
    "        # print(wi)\n",
    "    # print(losses)\n",
    "    \n",
    "    \n",
    "        \n",
    "    # raise NotImplementedError\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100  -50    0   50  100  150]\n",
      "[-150 -100  -50    0   50  100]\n"
     ]
    }
   ],
   "source": [
    "grid_w0 = np.arange(-100, 200, 50)\n",
    "grid_w1 = np.arange(-150, 150, 50)\n",
    "print(grid_w0)\n",
    "print(grid_w1)\n",
    "losses = grid_search(y, tx, grid_w0, grid_w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28393.58577822, 21469.60015647, 17045.61453472, 15121.62891297,\n",
       "        15697.64329122, 18773.65766947],\n",
       "       [20978.88967811, 14054.90405636,  9630.91843461,  7706.93281286,\n",
       "         8282.94719111, 11358.96156937],\n",
       "       [16064.19357801,  9140.20795626,  4716.22233451,  2792.23671276,\n",
       "         3368.25109101,  6444.26546926],\n",
       "       [13649.4974779 ,  6725.51185615,  2301.5262344 ,   377.54061265,\n",
       "          953.5549909 ,  4029.56936916],\n",
       "       [13734.8013778 ,  6810.81575605,  2386.8301343 ,   462.84451255,\n",
       "         1038.8588908 ,  4114.87326905],\n",
       "       [16320.10527769,  9396.11965594,  4972.13403419,  3048.14841244,\n",
       "         3624.16279069,  6700.17716894]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=15.55870336860953, w0*=72.72727272727272, w1*=13.636363636363626, execution time=46.084 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters\n",
    "from plots import grid_visualization\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=100)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    \"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "        l=loss_star, w0=w0_star, w1=w1_star, t=execution_time\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0, 6.0)\n",
    "fig.savefig(\"grid_plot\")  # Optional saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        An numpy array of shape (2, ) (same shape as w), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute gradient vector\n",
    "    # ***************************************************\n",
    "    e = y - (tx.dot(w))\n",
    "    gradient = - (tx.T).dot(e)/y.shape[0]\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26.706078    6.52028757]\n",
      "[-23.293922    -3.47971243]\n"
     ]
    }
   ],
   "source": [
    "wi = np.array([100,\n",
    "              20])\n",
    "wit = wi.T\n",
    "wii = np.array([50,\n",
    "                10])\n",
    "wiit = wii.T\n",
    "print(compute_gradient(y,tx,wit))\n",
    "print(compute_gradient(y,tx,wiit))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: compute gradient and loss\n",
    "        # ***************************************************\n",
    "        gradient = compute_gradient(y, tx, w)\n",
    "        loss = compute_loss(y, tx, w)\n",
    "\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: update w by gradient\n",
    "        # ***************************************************\n",
    "        w = w - gamma * gradient\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2792.2367127591674, w0=51.30574540147363, w1=9.435798704492282\n",
      "GD iter. 1/49: loss=265.30246210896007, w0=66.69746902191572, w1=12.266538315840002\n",
      "GD iter. 2/49: loss=37.87837955044118, w0=71.31498610804834, w1=13.11576019924433\n",
      "GD iter. 3/49: loss=17.41021212017447, w0=72.70024123388814, w1=13.37052676426563\n",
      "GD iter. 4/49: loss=15.568077051450457, w0=73.11581777164007, w1=13.446956733772023\n",
      "GD iter. 5/49: loss=15.402284895265295, w0=73.24049073296565, w1=13.469885724623941\n",
      "GD iter. 6/49: loss=15.38736360120863, w0=73.27789262136334, w1=13.476764421879516\n",
      "GD iter. 7/49: loss=15.38602068474353, w0=73.28911318788263, w1=13.478828031056189\n",
      "GD iter. 8/49: loss=15.385899822261674, w0=73.29247935783842, w1=13.47944711380919\n",
      "GD iter. 9/49: loss=15.385888944638305, w0=73.29348920882515, w1=13.47963283863509\n",
      "GD iter. 10/49: loss=15.3858879656522, w0=73.29379216412117, w1=13.479688556082861\n",
      "GD iter. 11/49: loss=15.385887877543452, w0=73.29388305070998, w1=13.479705271317192\n",
      "GD iter. 12/49: loss=15.385887869613665, w0=73.29391031668662, w1=13.479710285887492\n",
      "GD iter. 13/49: loss=15.385887868899983, w0=73.29391849647962, w1=13.479711790258582\n",
      "GD iter. 14/49: loss=15.38588786883575, w0=73.29392095041752, w1=13.479712241569908\n",
      "GD iter. 15/49: loss=15.385887868829974, w0=73.29392168659889, w1=13.479712376963306\n",
      "GD iter. 16/49: loss=15.38588786882945, w0=73.2939219074533, w1=13.479712417581325\n",
      "GD iter. 17/49: loss=15.385887868829403, w0=73.29392197370962, w1=13.479712429766732\n",
      "GD iter. 18/49: loss=15.3858878688294, w0=73.29392199358652, w1=13.479712433422353\n",
      "GD iter. 19/49: loss=15.385887868829403, w0=73.2939219995496, w1=13.47971243451904\n",
      "GD iter. 20/49: loss=15.385887868829398, w0=73.29392200133852, w1=13.479712434848047\n",
      "GD iter. 21/49: loss=15.3858878688294, w0=73.29392200187519, w1=13.479712434946748\n",
      "GD iter. 22/49: loss=15.3858878688294, w0=73.29392200203618, w1=13.479712434976358\n",
      "GD iter. 23/49: loss=15.3858878688294, w0=73.29392200208449, w1=13.479712434985242\n",
      "GD iter. 24/49: loss=15.3858878688294, w0=73.29392200209898, w1=13.479712434987906\n",
      "GD iter. 25/49: loss=15.385887868829398, w0=73.29392200210333, w1=13.479712434988706\n",
      "GD iter. 26/49: loss=15.3858878688294, w0=73.29392200210464, w1=13.479712434988945\n",
      "GD iter. 27/49: loss=15.3858878688294, w0=73.29392200210502, w1=13.479712434989018\n",
      "GD iter. 28/49: loss=15.3858878688294, w0=73.29392200210513, w1=13.47971243498904\n",
      "GD iter. 29/49: loss=15.3858878688294, w0=73.29392200210518, w1=13.479712434989047\n",
      "GD iter. 30/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 31/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 32/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 33/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 34/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 35/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 36/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 37/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 38/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 39/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 40/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 41/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 42/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 43/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 44/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 45/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 46/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 47/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 48/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 49/49: loss=15.3858878688294, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD: execution time=0.569 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4310725c8a49494894fc0a6fb63dd01b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from helpers import batch_iter\n",
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: implement stochastic gradient computation. It's the same as the usual gradient.\n",
    "    # ***************************************************\n",
    "    e = y - tx.dot(w)\n",
    "\n",
    "    return -tx.T.dot(e)\n",
    "    \n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: implement stochastic gradient descent.\n",
    "        # ***************************************************\n",
    "        for minibatch_y, minibatch_tx in batch_iter(y, tx, batch_size):\n",
    "            # print(batch_iter(y,tx,batch_size))\n",
    "            stochastic_grad = compute_stoch_gradient(minibatch_y, minibatch_tx, w)\n",
    "            w = w - gamma * stochastic_grad\n",
    "            loss= compute_loss(y,tx,w)\n",
    "            ws.append(w)\n",
    "            losses.append(loss)\n",
    "\n",
    "            print(\n",
    "            \"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "SGD iter. 0/49: loss=1675.2874085320318, w0=19.529924227097027, w1=-7.238289026911769\n",
      "(10000,)\n",
      "SGD iter. 1/49: loss=522.606213642901, w0=41.581759023529216, w1=16.442712733399148\n",
      "(10000,)\n",
      "SGD iter. 2/49: loss=274.8963688582443, w0=52.65335971553607, w1=3.836676062917711\n",
      "(10000,)\n",
      "SGD iter. 3/49: loss=90.59643521733169, w0=61.63728026536978, w1=9.666079243608053\n",
      "(10000,)\n",
      "SGD iter. 4/49: loss=66.75102716813186, w0=63.691848588849446, w1=10.234644675287848\n",
      "(10000,)\n",
      "SGD iter. 5/49: loss=43.56772229660562, w0=65.8535035067991, w1=14.481631329041605\n",
      "(10000,)\n",
      "SGD iter. 6/49: loss=25.626202154710313, w0=68.82665104153416, w1=12.75575198261568\n",
      "(10000,)\n",
      "SGD iter. 7/49: loss=23.134750388067285, w0=70.48252292395377, w1=10.724034612411613\n",
      "(10000,)\n",
      "SGD iter. 8/49: loss=19.574994143284123, w0=71.40913875428438, w1=11.28294101819496\n",
      "(10000,)\n",
      "SGD iter. 9/49: loss=16.03846151943205, w0=72.15576900926291, w1=13.380944696888667\n",
      "(10000,)\n",
      "SGD iter. 10/49: loss=16.578930770714422, w0=72.38818086060394, w1=12.22842558204043\n",
      "(10000,)\n",
      "SGD iter. 11/49: loss=18.525138052532302, w0=71.75061990987884, w1=11.505701538480222\n",
      "(10000,)\n",
      "SGD iter. 12/49: loss=18.656831137144227, w0=71.58281459510971, w1=11.578660626553816\n",
      "(10000,)\n",
      "SGD iter. 13/49: loss=16.117461903020043, w0=72.08507314252819, w1=13.436904689420388\n",
      "(10000,)\n",
      "SGD iter. 14/49: loss=16.4644436283171, w0=71.86108104526953, w1=13.157100731249605\n",
      "(10000,)\n",
      "SGD iter. 15/49: loss=16.145115084194416, w0=72.18678746156687, w1=12.938687907008083\n",
      "(10000,)\n",
      "SGD iter. 16/49: loss=15.643242630288514, w0=73.94403886879898, w1=13.783122359939554\n",
      "(10000,)\n",
      "SGD iter. 17/49: loss=17.6122706291842, w0=71.36114674343342, w1=12.632868104444238\n",
      "(10000,)\n",
      "SGD iter. 18/49: loss=16.026729416146186, w0=72.25670826973108, w1=13.933442275321525\n",
      "(10000,)\n",
      "SGD iter. 19/49: loss=15.91017163838938, w0=73.56403925018957, w1=14.46743922484912\n",
      "(10000,)\n",
      "SGD iter. 20/49: loss=17.180225346802278, w0=73.37625532243072, w1=15.372302242715469\n",
      "(10000,)\n",
      "SGD iter. 21/49: loss=18.191915597011192, w0=73.62629910134282, w1=15.82525734401679\n",
      "(10000,)\n",
      "SGD iter. 22/49: loss=17.51211798798709, w0=73.3866934229447, w1=15.539774012173282\n",
      "(10000,)\n",
      "SGD iter. 23/49: loss=17.22182212847581, w0=74.00405152256347, w1=15.259483370662094\n",
      "(10000,)\n",
      "SGD iter. 24/49: loss=17.727813858685096, w0=75.35552796454861, w1=14.138220472395668\n",
      "(10000,)\n",
      "SGD iter. 25/49: loss=19.22254180251937, w0=76.04749041339635, w1=13.177770599995226\n",
      "(10000,)\n",
      "SGD iter. 26/49: loss=18.273873288657562, w0=75.67551623248177, w1=13.802171364921701\n",
      "(10000,)\n",
      "SGD iter. 27/49: loss=18.81781032024307, w0=75.69242318298393, w1=14.533769828184807\n",
      "(10000,)\n",
      "SGD iter. 28/49: loss=22.312922278355686, w0=76.78806184006102, w1=14.76230964840509\n",
      "(10000,)\n",
      "SGD iter. 29/49: loss=28.33653233104662, w0=74.15114831693107, w1=8.463094852433601\n",
      "(10000,)\n",
      "SGD iter. 30/49: loss=28.785543815545534, w0=75.48581330129001, w1=8.78983776438322\n",
      "(10000,)\n",
      "SGD iter. 31/49: loss=26.078172362606537, w0=74.2913722834593, w1=8.964221108036812\n",
      "(10000,)\n",
      "SGD iter. 32/49: loss=24.063715945031387, w0=73.36808860568904, w1=9.31436065304832\n",
      "(10000,)\n",
      "SGD iter. 33/49: loss=19.601939804877144, w0=72.94382872719702, w1=10.597085409000503\n",
      "(10000,)\n",
      "SGD iter. 34/49: loss=17.53992761894809, w0=71.61834989509177, w1=12.254748103085465\n",
      "(10000,)\n",
      "SGD iter. 35/49: loss=16.950442530623906, w0=71.67923265143145, w1=14.202130336490544\n",
      "(10000,)\n",
      "SGD iter. 36/49: loss=16.175666774152823, w0=72.58626924550559, w1=14.51835837404809\n",
      "(10000,)\n",
      "SGD iter. 37/49: loss=17.805087938756646, w0=71.65055721462316, w1=14.941817874113957\n",
      "(10000,)\n",
      "SGD iter. 38/49: loss=17.00990104396882, w0=71.9329255971268, w1=14.661116318474598\n",
      "(10000,)\n",
      "SGD iter. 39/49: loss=16.190430755087256, w0=72.8648936760709, w1=14.673454646681309\n",
      "(10000,)\n",
      "SGD iter. 40/49: loss=17.596478319765815, w0=74.57846176564908, w1=11.815038743917002\n",
      "(10000,)\n",
      "SGD iter. 41/49: loss=16.99187794885843, w0=74.35772666459368, w1=12.037387991555535\n",
      "(10000,)\n",
      "SGD iter. 42/49: loss=18.31671598171156, w0=74.53562747198544, w1=11.401293865058104\n",
      "(10000,)\n",
      "SGD iter. 43/49: loss=16.45126453300471, w0=74.06798954691759, w1=12.242145158264776\n",
      "(10000,)\n",
      "SGD iter. 44/49: loss=16.464661940453983, w0=74.62310251518163, w1=12.854550610413188\n",
      "(10000,)\n",
      "SGD iter. 45/49: loss=17.878436469039777, w0=75.32626826345283, w1=12.555231026627034\n",
      "(10000,)\n",
      "SGD iter. 46/49: loss=19.407719219409625, w0=76.12729627823968, w1=13.354600834808325\n",
      "(10000,)\n",
      "SGD iter. 47/49: loss=17.959694779965176, w0=75.45643223429228, w1=12.793299062481136\n",
      "(10000,)\n",
      "SGD iter. 48/49: loss=15.795744533837574, w0=73.6683788561432, w1=12.655397328685456\n",
      "(10000,)\n",
      "SGD iter. 49/49: loss=15.457163385966076, w0=72.94627456408102, w1=13.332429397579471\n",
      "SGD: execution time=1.688 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "batch_size = 3\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10749c9a0cf488d8ae7612c7372b968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses,\n",
    "        sgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: reload the data by subsampling first, then by subsampling and adding outliers\n",
    "# ***************************************************\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=True)\n",
    "\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10002,), (10002, 2))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=2793.0633249190396, w0=51.31194997183169, w1=9.375829281932603\n",
      "GD iter. 1/49: loss=266.5853963287443, w0=66.70553496338118, w1=12.188578066512388\n",
      "GD iter. 2/49: loss=39.202382755617975, w0=71.32361046084604, w1=13.032402701886328\n",
      "GD iter. 3/49: loss=18.737911534036567, w0=72.70903311008549, w1=13.28555009249851\n",
      "GD iter. 4/49: loss=16.896109124094252, w0=73.12465990485732, w1=13.361494309682165\n",
      "GD iter. 5/49: loss=16.73034690719944, w0=73.24934794328888, w1=13.384277574837261\n",
      "GD iter. 6/49: loss=16.715428307678906, w0=73.28675435481834, w1=13.39111255438379\n",
      "GD iter. 7/49: loss=16.714085633722057, w0=73.29797627827718, w1=13.393163048247748\n",
      "GD iter. 8/49: loss=16.713964793065944, w0=73.30134285531483, w1=13.393778196406936\n",
      "GD iter. 9/49: loss=16.713953917406897, w0=73.30235282842612, w1=13.393962740854693\n",
      "GD iter. 10/49: loss=16.71395293859758, w0=73.30265582035952, w1=13.39401810418902\n",
      "GD iter. 11/49: loss=16.71395285050474, w0=73.30274671793954, w1=13.394034713189317\n",
      "GD iter. 12/49: loss=16.713952842576386, w0=73.30277398721354, w1=13.394039695889408\n",
      "GD iter. 13/49: loss=16.71395284186283, w0=73.30278216799574, w1=13.394041190699435\n",
      "GD iter. 14/49: loss=16.713952841798612, w0=73.3027846222304, w1=13.394041639142442\n",
      "GD iter. 15/49: loss=16.713952841792835, w0=73.3027853585008, w1=13.394041773675344\n",
      "GD iter. 16/49: loss=16.713952841792313, w0=73.30278557938192, w1=13.394041814035216\n",
      "GD iter. 17/49: loss=16.713952841792263, w0=73.30278564564625, w1=13.394041826143177\n",
      "GD iter. 18/49: loss=16.71395284179226, w0=73.30278566552556, w1=13.394041829775565\n",
      "GD iter. 19/49: loss=16.71395284179226, w0=73.30278567148935, w1=13.394041830865282\n",
      "GD iter. 20/49: loss=16.71395284179226, w0=73.30278567327848, w1=13.394041831192197\n",
      "GD iter. 21/49: loss=16.71395284179226, w0=73.30278567381522, w1=13.394041831290272\n",
      "GD iter. 22/49: loss=16.71395284179226, w0=73.30278567397625, w1=13.394041831319694\n",
      "GD iter. 23/49: loss=16.71395284179226, w0=73.30278567402455, w1=13.39404183132852\n",
      "GD iter. 24/49: loss=16.71395284179226, w0=73.30278567403904, w1=13.394041831331169\n",
      "GD iter. 25/49: loss=16.71395284179226, w0=73.30278567404339, w1=13.394041831331963\n",
      "GD iter. 26/49: loss=16.71395284179226, w0=73.3027856740447, w1=13.394041831332201\n",
      "GD iter. 27/49: loss=16.71395284179226, w0=73.30278567404508, w1=13.394041831332272\n",
      "GD iter. 28/49: loss=16.71395284179226, w0=73.30278567404521, w1=13.394041831332293\n",
      "GD iter. 29/49: loss=16.71395284179226, w0=73.30278567404524, w1=13.3940418313323\n",
      "GD iter. 30/49: loss=16.71395284179226, w0=73.30278567404525, w1=13.394041831332302\n",
      "GD iter. 31/49: loss=16.71395284179226, w0=73.30278567404525, w1=13.394041831332302\n",
      "GD iter. 32/49: loss=16.71395284179226, w0=73.30278567404525, w1=13.394041831332302\n",
      "GD iter. 33/49: loss=16.71395284179226, w0=73.30278567404525, w1=13.394041831332302\n",
      "GD iter. 34/49: loss=16.71395284179226, w0=73.30278567404525, w1=13.394041831332302\n",
      "GD iter. 35/49: loss=16.71395284179226, w0=73.30278567404525, w1=13.394041831332302\n",
      "GD iter. 36/49: loss=16.71395284179226, w0=73.30278567404525, w1=13.394041831332302\n",
      "GD iter. 37/49: loss=16.71395284179226, w0=73.30278567404525, w1=13.394041831332302\n",
      "GD iter. 38/49: loss=16.71395284179226, w0=73.30278567404525, w1=13.394041831332302\n",
      "GD iter. 39/49: loss=16.71395284179226, w0=73.30278567404525, w1=13.394041831332302\n",
      "GD iter. 40/49: loss=16.71395284179226, w0=73.30278567404525, w1=13.394041831332302\n",
      "GD iter. 41/49: loss=16.71395284179226, w0=73.30278567404525, w1=13.394041831332302\n",
      "GD iter. 42/49: loss=16.71395284179226, w0=73.30278567404525, w1=13.394041831332302\n",
      "GD iter. 43/49: loss=16.71395284179226, w0=73.30278567404525, w1=13.394041831332302\n",
      "GD iter. 44/49: loss=16.71395284179226, w0=73.30278567404525, w1=13.394041831332302\n",
      "GD iter. 45/49: loss=16.71395284179226, w0=73.30278567404525, w1=13.394041831332302\n",
      "GD iter. 46/49: loss=16.71395284179226, w0=73.30278567404525, w1=13.394041831332302\n",
      "GD iter. 47/49: loss=16.71395284179226, w0=73.30278567404525, w1=13.394041831332302\n",
      "GD iter. 48/49: loss=16.71395284179226, w0=73.30278567404525, w1=13.394041831332302\n",
      "GD iter. 49/49: loss=16.71395284179226, w0=73.30278567404525, w1=13.394041831332302\n",
      "GD: execution time=0.585 seconds\n"
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: fit the model to the subsampled data / subsampled data with outliers and visualize the cloud of points\n",
    "#       and the model fit\n",
    "# ***************************************************\n",
    "\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b872a51c67164628a08615441d4a0eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def compute_mae(y, tx, w):\n",
    "    e = y - tx.dot(w)\n",
    "\n",
    "    mae = np.mean(np.abs(e))\n",
    "    return mae\n",
    "\n",
    "\n",
    "# def sign_e(e):\n",
    "#     if e > 0:\n",
    "#         sign = 1\n",
    "        \n",
    "#     else if e = 0:\n",
    "#         sign = 0\n",
    "    \n",
    "#     else:\n",
    "#         sign = -1\n",
    "#     return sign\n",
    "\n",
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute subgradient gradient vector for MAE\n",
    "    # ***************************************************\n",
    "    e = y - tx.dot(w)\n",
    "    subgradient = - tx.T.dot(np.sign(e))/y.shape[0]\n",
    "    \n",
    "    return subgradient\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# help(np.sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: compute subgradient and loss\n",
    "        # ***************************************************\n",
    "        subgrad = compute_subgradient_mae(y, tx, w)\n",
    "        loss = compute_mae(y, tx, w)\n",
    "        \n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: update w by subgradient\n",
    "        # ***************************************************\n",
    "        w = w - gamma * subgrad\n",
    "\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 0/499: loss=73.30278567404525, w0=0.7, w1=-1.2332555381718993e-16\n",
      "SubGD iter. 1/499: loss=72.60278567404525, w0=1.4, w1=-2.4665110763437986e-16\n",
      "SubGD iter. 2/499: loss=71.90278567404525, w0=2.0999999999999996, w1=-3.699766614515698e-16\n",
      "SubGD iter. 3/499: loss=71.20278567404526, w0=2.8, w1=-4.933022152687597e-16\n",
      "SubGD iter. 4/499: loss=70.50278567404526, w0=3.5, w1=-6.166277690859497e-16\n",
      "SubGD iter. 5/499: loss=69.80278567404525, w0=4.2, w1=-7.399533229031396e-16\n",
      "SubGD iter. 6/499: loss=69.10278567404525, w0=4.9, w1=-8.632788767203295e-16\n",
      "SubGD iter. 7/499: loss=68.40278567404525, w0=5.6000000000000005, w1=-9.866044305375195e-16\n",
      "SubGD iter. 8/499: loss=67.70278567404526, w0=6.300000000000001, w1=-1.1099299843547093e-15\n",
      "SubGD iter. 9/499: loss=67.00278567404526, w0=7.000000000000001, w1=-1.2332555381718991e-15\n",
      "SubGD iter. 10/499: loss=66.30278567404525, w0=7.700000000000001, w1=-1.356581091989089e-15\n",
      "SubGD iter. 11/499: loss=65.60278567404525, w0=8.4, w1=-1.4799066458062788e-15\n",
      "SubGD iter. 12/499: loss=64.90278567404525, w0=9.1, w1=-1.6032321996234686e-15\n",
      "SubGD iter. 13/499: loss=64.20278567404526, w0=9.799999999999999, w1=-1.7265577534406585e-15\n",
      "SubGD iter. 14/499: loss=63.50278567404526, w0=10.499999999999998, w1=-1.8498833072578483e-15\n",
      "SubGD iter. 15/499: loss=62.802785674045246, w0=11.199999999999998, w1=-1.973208861075038e-15\n",
      "SubGD iter. 16/499: loss=62.10278567404526, w0=11.899999999999997, w1=-2.096534414892228e-15\n",
      "SubGD iter. 17/499: loss=61.40278567404527, w0=12.599999999999996, w1=-2.2198599687094178e-15\n",
      "SubGD iter. 18/499: loss=60.70278567404525, w0=13.299999999999995, w1=-2.3431855225266076e-15\n",
      "SubGD iter. 19/499: loss=60.00278567404526, w0=13.999999999999995, w1=-2.4665110763437975e-15\n",
      "SubGD iter. 20/499: loss=59.30278567404527, w0=14.699999999999994, w1=-2.5898366301609873e-15\n",
      "SubGD iter. 21/499: loss=58.60278567404526, w0=15.399999999999993, w1=-2.713162183978177e-15\n",
      "SubGD iter. 22/499: loss=57.90278567404527, w0=16.099999999999994, w1=-2.836487737795367e-15\n",
      "SubGD iter. 23/499: loss=57.20278567404525, w0=16.799999999999994, w1=-2.9598132916125568e-15\n",
      "SubGD iter. 24/499: loss=56.50278567404526, w0=17.499999999999993, w1=-3.0831388454297466e-15\n",
      "SubGD iter. 25/499: loss=55.80278567404527, w0=18.199999999999992, w1=-3.2064643992469365e-15\n",
      "SubGD iter. 26/499: loss=55.10278567404527, w0=18.89999999999999, w1=-3.3297899530641263e-15\n",
      "SubGD iter. 27/499: loss=54.40278567404527, w0=19.59999999999999, w1=-3.453115506881316e-15\n",
      "SubGD iter. 28/499: loss=53.702785674045266, w0=20.29999999999999, w1=-3.576441060698506e-15\n",
      "SubGD iter. 29/499: loss=53.00278567404527, w0=20.99999999999999, w1=-3.6997666145156966e-15\n",
      "SubGD iter. 30/499: loss=52.30278567404527, w0=21.69999999999999, w1=-3.823092168332887e-15\n",
      "SubGD iter. 31/499: loss=51.602785674045265, w0=22.399999999999988, w1=-3.946417722150077e-15\n",
      "SubGD iter. 32/499: loss=50.90278567404527, w0=23.099999999999987, w1=-4.069743275967267e-15\n",
      "SubGD iter. 33/499: loss=50.202785674045266, w0=23.799999999999986, w1=-4.1930688297844575e-15\n",
      "SubGD iter. 34/499: loss=49.50278567404527, w0=24.499999999999986, w1=-4.316394383601648e-15\n",
      "SubGD iter. 35/499: loss=48.80278567404527, w0=25.199999999999985, w1=-4.439719937418838e-15\n",
      "SubGD iter. 36/499: loss=48.10278567404527, w0=25.899999999999984, w1=-4.563045491236028e-15\n",
      "SubGD iter. 37/499: loss=47.402785674045276, w0=26.599999999999984, w1=-4.6863710450532184e-15\n",
      "SubGD iter. 38/499: loss=46.70278567404527, w0=27.299999999999983, w1=-4.809696598870409e-15\n",
      "SubGD iter. 39/499: loss=46.00278567404527, w0=27.999999999999982, w1=-4.933022152687599e-15\n",
      "SubGD iter. 40/499: loss=45.30278567404527, w0=28.69999999999998, w1=-5.056347706504789e-15\n",
      "SubGD iter. 41/499: loss=44.60278567404528, w0=29.39999999999998, w1=-5.179673260321979e-15\n",
      "SubGD iter. 42/499: loss=43.90279090149427, w0=30.09986002799438, w1=0.0004390332530533584\n",
      "SubGD iter. 43/499: loss=43.20307054215923, w0=30.799720055988782, w1=0.0008780665061118965\n",
      "SubGD iter. 44/499: loss=42.50335018282421, w0=31.499580083983183, w1=0.0013170997591704346\n",
      "SubGD iter. 45/499: loss=41.80366538836426, w0=32.19930013997199, w1=0.0021441866048852194\n",
      "SubGD iter. 46/499: loss=41.1042241871848, w0=32.899020195960794, w1=0.0029712734506000043\n",
      "SubGD iter. 47/499: loss=40.404878409135, w0=33.598600279943994, w1=0.004224559476621934\n",
      "SubGD iter. 48/499: loss=39.70582775649904, w0=34.298040391921596, w1=0.005804766748670344\n",
      "SubGD iter. 49/499: loss=39.006943517501526, w0=34.9974805038992, w1=0.007384974020718754\n",
      "SubGD iter. 50/499: loss=38.30805927850401, w0=35.6969206158768, w1=0.008965181292767164\n",
      "SubGD iter. 51/499: loss=37.60933290053714, w0=36.3960807838432, w1=0.011211104070244973\n",
      "SubGD iter. 52/499: loss=36.91122396333907, w0=37.09496100779841, w1=0.014222184655636138\n",
      "SubGD iter. 53/499: loss=36.21354794498195, w0=37.79370125974802, w1=0.017605329057828974\n",
      "SubGD iter. 54/499: loss=35.516150538267645, w0=38.49216156768643, w1=0.021516730245136\n",
      "SubGD iter. 55/499: loss=34.8193340753224, w0=39.190201959608046, w1=0.02646219697935598\n",
      "SubGD iter. 56/499: loss=34.12350060982031, w0=39.88740251949607, w1=0.033348128333762495\n",
      "SubGD iter. 57/499: loss=33.42921022861568, w0=40.5840431913617, w1=0.04141548114171521\n",
      "SubGD iter. 58/499: loss=32.735943241011256, w0=41.28012397520493, w1=0.05097899237356002\n",
      "SubGD iter. 59/499: loss=32.04426837406425, w0=41.97494501099777, w1=0.06329961379535383\n",
      "SubGD iter. 60/499: loss=31.355246976100393, w0=42.667806438712226, w1=0.07978094219757825\n",
      "SubGD iter. 61/499: loss=30.669804828344038, w0=43.3591281743651, w1=0.09929806319975969\n",
      "SubGD iter. 62/499: loss=29.987238795200668, w0=44.04877024595078, w1=0.12242622134166117\n",
      "SubGD iter. 63/499: loss=29.30819127409112, w0=44.73561287742448, w1=0.15100859237468173\n",
      "SubGD iter. 64/499: loss=28.634376059644197, w0=45.41979604079181, w1=0.18456407916033185\n",
      "SubGD iter. 65/499: loss=27.965426108352656, w0=46.100619876024766, w1=0.22448157906915986\n",
      "SubGD iter. 66/499: loss=27.302245652315086, w0=46.77836432713455, w1=0.269732014107414\n",
      "SubGD iter. 67/499: loss=26.645005064767513, w0=47.45232953409315, w1=0.32130192698519267\n",
      "SubGD iter. 68/499: loss=25.995455071008934, w0=48.11985602879421, w1=0.38338978824408276\n",
      "SubGD iter. 69/499: loss=25.355511013112146, w0=48.78248350329931, w1=0.453386602496482\n",
      "SubGD iter. 70/499: loss=24.72261768960264, w0=49.44133173365324, w1=0.5297174602200958\n",
      "SubGD iter. 71/499: loss=24.09622474876779, w0=50.09458108378322, w1=0.6150057665180065\n",
      "SubGD iter. 72/499: loss=23.47846228709086, w0=50.741531693661244, w1=0.709715506684579\n",
      "SubGD iter. 73/499: loss=22.8698451828384, w0=51.38190361927612, w1=0.8143067463296961\n",
      "SubGD iter. 74/499: loss=22.270276533534847, w0=52.01541691661666, w1=0.9287549135079824\n",
      "SubGD iter. 75/499: loss=21.680365705378453, w0=52.641791641671645, w1=1.0533715069904093\n",
      "SubGD iter. 76/499: loss=21.100080538043457, w0=53.260747850429894, w1=1.1878295503598069\n",
      "SubGD iter. 77/499: loss=20.52901238908139, w0=53.873125374924996, w1=1.3317700853243954\n",
      "SubGD iter. 78/499: loss=19.965744745040404, w0=54.47822435512896, w1=1.4851730325164136\n",
      "SubGD iter. 79/499: loss=19.411297235216406, w0=55.07548490301938, w1=1.6486010251013725\n",
      "SubGD iter. 80/499: loss=18.866209029569067, w0=55.66364727054587, w1=1.8228431330769275\n",
      "SubGD iter. 81/499: loss=18.331186917424247, w0=56.24243151369724, w1=2.0081856078826092\n",
      "SubGD iter. 82/499: loss=17.80534835848199, w0=56.813517296540674, w1=2.2021065222377607\n",
      "SubGD iter. 83/499: loss=17.288285799174773, w0=57.37452509498099, w1=2.405642025817045\n",
      "SubGD iter. 84/499: loss=16.781283861171776, w0=57.92727454509097, w1=2.617432977366366\n",
      "SubGD iter. 85/499: loss=16.283236195850762, w0=58.471205758848214, w1=2.837551090137762\n",
      "SubGD iter. 86/499: loss=15.793328578504715, w0=59.00617876424713, w1=3.066388708143779\n",
      "SubGD iter. 87/499: loss=15.311789519155491, w0=59.531773645270924, w1=3.3044328747838345\n",
      "SubGD iter. 88/499: loss=14.838063725481062, w0=60.049390121975584, w1=3.5489669244691435\n",
      "SubGD iter. 89/499: loss=14.372800818102991, w0=60.55496900619874, w1=3.8028126363236816\n",
      "SubGD iter. 90/499: loss=13.917539527499239, w0=61.052429514097156, w1=4.062481967409632\n",
      "SubGD iter. 91/499: loss=13.469229899380228, w0=61.54219156168764, w1=4.328013364242923\n",
      "SubGD iter. 92/499: loss=13.02750387447573, w0=62.02299540091979, w1=4.599633379203242\n",
      "SubGD iter. 93/499: loss=12.59369511086245, w0=62.49484103179361, w1=4.878291050974949\n",
      "SubGD iter. 94/499: loss=12.167034901224856, w0=62.95758848230351, w1=5.1616188421531914\n",
      "SubGD iter. 95/499: loss=11.748458089640712, w0=63.41067786442708, w1=5.449329378501437\n",
      "SubGD iter. 96/499: loss=11.339016796427229, w0=63.85494901019793, w1=5.740885365949973\n",
      "SubGD iter. 97/499: loss=10.937634902165168, w0=64.29110177964404, w1=6.035625156501035\n",
      "SubGD iter. 98/499: loss=10.544417274915903, w0=64.71619676064783, w1=6.333201492316891\n",
      "SubGD iter. 99/499: loss=10.162154052689308, w0=65.13177364527091, w1=6.632632773794741\n",
      "SubGD iter. 100/499: loss=9.790025799875291, w0=65.53727254549086, w1=6.9327920605249576\n",
      "SubGD iter. 101/499: loss=9.428673303391081, w0=65.9339532093581, w1=7.233414234721268\n",
      "SubGD iter. 102/499: loss=9.077528070070953, w0=66.320275944811, w1=7.535584854277058\n",
      "SubGD iter. 103/499: loss=8.73660454491059, w0=66.6969406118776, w1=7.838442184331338\n",
      "SubGD iter. 104/499: loss=8.405415515963762, w0=67.06226754649067, w1=8.141614439592079\n",
      "SubGD iter. 105/499: loss=8.086211835593977, w0=67.41891621675661, w1=8.443320496246868\n",
      "SubGD iter. 106/499: loss=7.776283229166312, w0=67.7694061187762, w1=8.743057731565969\n",
      "SubGD iter. 107/499: loss=7.475677159816825, w0=68.1077184563087, w1=9.04141481718868\n",
      "SubGD iter. 108/499: loss=7.187521233784825, w0=68.43693261347727, w1=9.336737930365242\n",
      "SubGD iter. 109/499: loss=6.910812975630425, w0=68.7583083383323, w1=9.628219259354854\n",
      "SubGD iter. 110/499: loss=6.6455896083332515, w0=69.0701659668066, w1=9.912384627099724\n",
      "SubGD iter. 111/499: loss=6.395300839394458, w0=69.3688662267546, w1=10.191577499035187\n",
      "SubGD iter. 112/499: loss=6.161053007118128, w0=69.65328934213153, w1=10.463672134401827\n",
      "SubGD iter. 113/499: loss=5.94381778395154, w0=69.92679464107174, w1=10.726390556476394\n",
      "SubGD iter. 114/499: loss=5.7425697030521565, w0=70.18924215156964, w1=10.978380557628476\n",
      "SubGD iter. 115/499: loss=5.558345173696266, w0=70.43685262947406, w1=11.219701967428096\n",
      "SubGD iter. 116/499: loss=5.391641405544889, w0=70.67284543091377, w1=11.449165318666559\n",
      "SubGD iter. 117/499: loss=5.24071889508463, w0=70.89652069586077, w1=11.666356516752096\n",
      "SubGD iter. 118/499: loss=5.106634969758831, w0=71.1056388722255, w1=11.867108883130133\n",
      "SubGD iter. 119/499: loss=4.991153785383381, w0=71.30033993201354, w1=12.051407766868662\n",
      "SubGD iter. 120/499: loss=4.892981370963165, w0=71.48048390321931, w1=12.217845301729664\n",
      "SubGD iter. 121/499: loss=4.81070100708957, w0=71.64621075784838, w1=12.368249551058984\n",
      "SubGD iter. 122/499: loss=4.742187093277622, w0=71.79696060787838, w1=12.502401790610863\n",
      "SubGD iter. 123/499: loss=4.686487678622182, w0=71.93525294941007, w1=12.626956346855325\n",
      "SubGD iter. 124/499: loss=4.639437199308804, w0=72.06220755848825, w1=12.737690959456451\n",
      "SubGD iter. 125/499: loss=4.601008741674444, w0=72.17670465906814, w1=12.834789566779996\n",
      "SubGD iter. 126/499: loss=4.570878857193654, w0=72.27916416716651, w1=12.920166995931814\n",
      "SubGD iter. 127/499: loss=4.546615654006647, w0=72.37210557888417, w1=12.996860468282232\n",
      "SubGD iter. 128/499: loss=4.526806348054851, w0=72.4574885022995, w1=13.065076915423859\n",
      "SubGD iter. 129/499: loss=4.510505644690025, w0=72.53475304939008, w1=13.124849343844442\n",
      "SubGD iter. 130/499: loss=4.4975945330323475, w0=72.60459908018392, w1=13.178183638705837\n",
      "SubGD iter. 131/499: loss=4.487265381895138, w0=72.66660667866422, w1=13.224139301602635\n",
      "SubGD iter. 132/499: loss=4.479191712113414, w0=72.72133573285339, w1=13.264864394964698\n",
      "SubGD iter. 133/499: loss=4.472817519440569, w0=72.77186562687459, w1=13.30091509114702\n",
      "SubGD iter. 134/499: loss=4.4675561827419745, w0=72.81763647270542, w1=13.333500176263556\n",
      "SubGD iter. 135/499: loss=4.463288757061997, w0=72.85850829834028, w1=13.361656909184125\n",
      "SubGD iter. 136/499: loss=4.459997179178853, w0=72.89518096380719, w1=13.385470159777041\n",
      "SubGD iter. 137/499: loss=4.457404802434001, w0=72.92821435712852, w1=13.406736705866416\n",
      "SubGD iter. 138/499: loss=4.455328990567886, w0=72.9574685062987, w1=13.424351640528354\n",
      "SubGD iter. 139/499: loss=4.453735750777075, w0=72.98448310337928, w1=13.439983794143533\n",
      "SubGD iter. 140/499: loss=4.4523968500320965, w0=73.00925814837028, w1=13.45411035086824\n",
      "SubGD iter. 141/499: loss=4.45131975962423, w0=73.0310937812437, w1=13.465384196687685\n",
      "SubGD iter. 142/499: loss=4.450506540762972, w0=73.05026994601074, w1=13.477028241909224\n",
      "SubGD iter. 143/499: loss=4.449814858309298, w0=73.0681863627274, w1=13.488161740639182\n",
      "SubGD iter. 144/499: loss=4.449213652205449, w0=73.08442311537688, w1=13.49771172811726\n",
      "SubGD iter. 145/499: loss=4.448745137906948, w0=73.09856028794236, w1=13.506048564348895\n",
      "SubGD iter. 146/499: loss=4.44838765851746, w0=73.11129774045186, w1=13.513115848283256\n",
      "SubGD iter. 147/499: loss=4.44810514252056, w0=73.12249550089977, w1=13.5191443480512\n",
      "SubGD iter. 148/499: loss=4.447886975692217, w0=73.1328534293141, w1=13.524593524222752\n",
      "SubGD iter. 149/499: loss=4.447696889436357, w0=73.14279144171162, w1=13.52973999124479\n",
      "SubGD iter. 150/499: loss=4.44752928762417, w0=73.15188962207554, w1=13.53383204216614\n",
      "SubGD iter. 151/499: loss=4.447392220957329, w0=73.16000799840027, w1=13.537979284490284\n",
      "SubGD iter. 152/499: loss=4.447288411746005, w0=73.16686662667462, w1=13.541214002705695\n",
      "SubGD iter. 153/499: loss=4.447212805986192, w0=73.17274545090977, w1=13.543637004539578\n",
      "SubGD iter. 154/499: loss=4.447158458314936, w0=73.17806438712253, w1=13.545916766781724\n",
      "SubGD iter. 155/499: loss=4.447112353324508, w0=73.1829634073185, w1=13.547677121744794\n",
      "SubGD iter. 156/499: loss=4.44707612974491, w0=73.18744251149766, w1=13.54919080283612\n",
      "SubGD iter. 157/499: loss=4.447047662411336, w0=73.19136172765444, w1=13.550424348030843\n",
      "SubGD iter. 158/499: loss=4.447027666957924, w0=73.19458108378322, w1=13.550589303562214\n",
      "SubGD iter. 159/499: loss=4.447013436352964, w0=73.19766046790639, w1=13.550645922422449\n",
      "SubGD iter. 160/499: loss=4.44700008686238, w0=73.20059988002396, w1=13.550749965492663\n",
      "SubGD iter. 161/499: loss=4.446988333131259, w0=73.20297940411913, w1=13.551661450201802\n",
      "SubGD iter. 162/499: loss=4.446979289599208, w0=73.20521895620871, w1=13.552523723725939\n",
      "SubGD iter. 163/499: loss=4.446971190081191, w0=73.20731853629269, w1=13.553404406621754\n",
      "SubGD iter. 164/499: loss=4.446963910158022, w0=73.20927814437107, w1=13.55410460736463\n",
      "SubGD iter. 165/499: loss=4.446957723951019, w0=73.21123775244945, w1=13.554804808107507\n",
      "SubGD iter. 166/499: loss=4.4469518281536775, w0=73.21277744451103, w1=13.5549916568736\n",
      "SubGD iter. 167/499: loss=4.446948493036612, w0=73.21417716456702, w1=13.555015938361008\n",
      "SubGD iter. 168/499: loss=4.446945693314005, w0=73.215576884623, w1=13.555040219848415\n",
      "SubGD iter. 169/499: loss=4.4469436348663525, w0=73.2164167166566, w1=13.554832133791885\n",
      "SubGD iter. 170/499: loss=4.446942565412565, w0=73.21725654869019, w1=13.554624047735356\n",
      "SubGD iter. 171/499: loss=4.446941495958777, w0=73.21809638072378, w1=13.554415961678826\n",
      "SubGD iter. 172/499: loss=4.446940426504988, w0=73.21893621275737, w1=13.554207875622296\n",
      "SubGD iter. 173/499: loss=4.446939399385572, w0=73.21963607278536, w1=13.554278368545425\n",
      "SubGD iter. 174/499: loss=4.446938692566556, w0=73.22033593281336, w1=13.554348861468554\n",
      "SubGD iter. 175/499: loss=4.446938075957788, w0=73.22089582083575, w1=13.554362759813328\n",
      "SubGD iter. 176/499: loss=4.446937656956472, w0=73.22131573685255, w1=13.554443486398297\n",
      "SubGD iter. 177/499: loss=4.446937395747552, w0=73.22173565286934, w1=13.554524212983265\n",
      "SubGD iter. 178/499: loss=4.446937134538634, w0=73.22215556888614, w1=13.554604939568234\n",
      "SubGD iter. 179/499: loss=4.446936873329715, w0=73.22257548490293, w1=13.554685666153203\n",
      "SubGD iter. 180/499: loss=4.4469366121207985, w0=73.22299540091973, w1=13.554766392738172\n",
      "SubGD iter. 181/499: loss=4.44693635091188, w0=73.22341531693652, w1=13.55484711932314\n",
      "SubGD iter. 182/499: loss=4.4469360897029615, w0=73.22383523295332, w1=13.554927845908109\n",
      "SubGD iter. 183/499: loss=4.446935835663585, w0=73.22411517696452, w1=13.55528437783236\n",
      "SubGD iter. 184/499: loss=4.446935619444646, w0=73.22453509298131, w1=13.555365104417328\n",
      "SubGD iter. 185/499: loss=4.446935358235726, w0=73.22495500899811, w1=13.555445831002297\n",
      "SubGD iter. 186/499: loss=4.446935138398825, w0=73.2250949810037, w1=13.555728188027041\n",
      "SubGD iter. 187/499: loss=4.446935052788593, w0=73.2253749250149, w1=13.555734739712502\n",
      "SubGD iter. 188/499: loss=4.446934940772058, w0=73.2256548690261, w1=13.555741291397963\n",
      "SubGD iter. 189/499: loss=4.446934879275782, w0=73.2257948410317, w1=13.556023648422707\n",
      "SubGD iter. 190/499: loss=4.446934770135181, w0=73.2260747850429, w1=13.556030200108168\n",
      "SubGD iter. 191/499: loss=4.446934678773079, w0=73.2262147570485, w1=13.556312557132912\n",
      "SubGD iter. 192/499: loss=4.446934599498306, w0=73.22649470105969, w1=13.556319108818373\n",
      "SubGD iter. 193/499: loss=4.446934487481772, w0=73.22677464507089, w1=13.556325660503834\n",
      "SubGD iter. 194/499: loss=4.446934419650038, w0=73.22691461707649, w1=13.556608017528578\n",
      "SubGD iter. 195/499: loss=4.446934383436222, w0=73.22691461707649, w1=13.556391309633817\n",
      "SubGD iter. 196/499: loss=4.446934374238628, w0=73.22691461707649, w1=13.556694814440789\n",
      "SubGD iter. 197/499: loss=4.446934410418166, w0=73.22705458908209, w1=13.5564569587638\n",
      "SubGD iter. 198/499: loss=4.446934385100931, w0=73.22691461707649, w1=13.55651605620832\n",
      "SubGD iter. 199/499: loss=4.4469343549665865, w0=73.22691461707649, w1=13.556299348313559\n",
      "SubGD iter. 200/499: loss=4.446934414111062, w0=73.22691461707649, w1=13.55660285312053\n",
      "SubGD iter. 201/499: loss=4.44693438183741, w0=73.22691461707649, w1=13.556386145225769\n",
      "SubGD iter. 202/499: loss=4.446934376477804, w0=73.22691461707649, w1=13.556689650032741\n",
      "SubGD iter. 203/499: loss=4.446934408708233, w0=73.22691461707649, w1=13.55647294213798\n",
      "SubGD iter. 204/499: loss=4.446934355762732, w0=73.22677464507089, w1=13.5565320395825\n",
      "SubGD iter. 205/499: loss=4.4469343830970764, w0=73.22691461707649, w1=13.55629418390551\n",
      "SubGD iter. 206/499: loss=4.446934416350236, w0=73.22691461707649, w1=13.556597688712483\n",
      "SubGD iter. 207/499: loss=4.4469343802385985, w0=73.22691461707649, w1=13.556380980817721\n",
      "SubGD iter. 208/499: loss=4.446934378716979, w0=73.22691461707649, w1=13.556684485624693\n",
      "SubGD iter. 209/499: loss=4.446934407109422, w0=73.22691461707649, w1=13.556467777729932\n",
      "SubGD iter. 210/499: loss=4.446934356198737, w0=73.22677464507089, w1=13.556526875174452\n",
      "SubGD iter. 211/499: loss=4.446934381342244, w0=73.22691461707649, w1=13.556289019497463\n",
      "SubGD iter. 212/499: loss=4.446934418589412, w0=73.22691461707649, w1=13.556592524304435\n",
      "SubGD iter. 213/499: loss=4.446934378639788, w0=73.22691461707649, w1=13.556375816409673\n",
      "SubGD iter. 214/499: loss=4.446934380956154, w0=73.22691461707649, w1=13.556679321216645\n",
      "SubGD iter. 215/499: loss=4.446934405510611, w0=73.22691461707649, w1=13.556462613321884\n",
      "SubGD iter. 216/499: loss=4.446934356634742, w0=73.22677464507089, w1=13.556521710766404\n",
      "SubGD iter. 217/499: loss=4.446934379587409, w0=73.22691461707649, w1=13.556283855089415\n",
      "SubGD iter. 218/499: loss=4.446934420828587, w0=73.22691461707649, w1=13.556587359896387\n",
      "SubGD iter. 219/499: loss=4.446934377040976, w0=73.22691461707649, w1=13.556370652001625\n",
      "SubGD iter. 220/499: loss=4.446934383195329, w0=73.22691461707649, w1=13.556674156808597\n",
      "SubGD iter. 221/499: loss=4.446934403911799, w0=73.22691461707649, w1=13.556457448913836\n",
      "SubGD iter. 222/499: loss=4.446934357070747, w0=73.22677464507089, w1=13.556516546358356\n",
      "SubGD iter. 223/499: loss=4.446934377832575, w0=73.22691461707649, w1=13.556278690681367\n",
      "SubGD iter. 224/499: loss=4.446934423067762, w0=73.22691461707649, w1=13.556582195488339\n",
      "SubGD iter. 225/499: loss=4.446934375442164, w0=73.22691461707649, w1=13.556365487593578\n",
      "SubGD iter. 226/499: loss=4.446934385434505, w0=73.22691461707649, w1=13.55666899240055\n",
      "SubGD iter. 227/499: loss=4.446934402312987, w0=73.22691461707649, w1=13.556452284505788\n",
      "SubGD iter. 228/499: loss=4.446934357506751, w0=73.22677464507089, w1=13.556511381950308\n",
      "SubGD iter. 229/499: loss=4.446934376077741, w0=73.22691461707649, w1=13.55627352627332\n",
      "SubGD iter. 230/499: loss=4.446934425306938, w0=73.22691461707649, w1=13.556577031080291\n",
      "SubGD iter. 231/499: loss=4.446934373843353, w0=73.22691461707649, w1=13.55636032318553\n",
      "SubGD iter. 232/499: loss=4.4469343876736795, w0=73.22691461707649, w1=13.556663827992502\n",
      "SubGD iter. 233/499: loss=4.446934400714176, w0=73.22691461707649, w1=13.55644712009774\n",
      "SubGD iter. 234/499: loss=4.446934357942757, w0=73.22677464507089, w1=13.55650621754226\n",
      "SubGD iter. 235/499: loss=4.446934374322907, w0=73.22691461707649, w1=13.556268361865271\n",
      "SubGD iter. 236/499: loss=4.446934427546112, w0=73.22691461707649, w1=13.556571866672243\n",
      "SubGD iter. 237/499: loss=4.446934372244542, w0=73.22691461707649, w1=13.556355158777482\n",
      "SubGD iter. 238/499: loss=4.4469343899128555, w0=73.22691461707649, w1=13.556658663584454\n",
      "SubGD iter. 239/499: loss=4.4469343991153645, w0=73.22691461707649, w1=13.556441955689692\n",
      "SubGD iter. 240/499: loss=4.446934358378761, w0=73.22677464507089, w1=13.556501053134212\n",
      "SubGD iter. 241/499: loss=4.446934373823641, w0=73.22705458908209, w1=13.556507604819673\n",
      "SubGD iter. 242/499: loss=4.446934380825142, w0=73.22691461707649, w1=13.556566702264194\n",
      "SubGD iter. 243/499: loss=4.44693437064573, w0=73.22691461707649, w1=13.556349994369432\n",
      "SubGD iter. 244/499: loss=4.446934392152031, w0=73.22691461707649, w1=13.556653499176404\n",
      "SubGD iter. 245/499: loss=4.446934397516553, w0=73.22691461707649, w1=13.556436791281643\n",
      "SubGD iter. 246/499: loss=4.446934358814765, w0=73.22677464507089, w1=13.556495888726163\n",
      "SubGD iter. 247/499: loss=4.446934373871978, w0=73.22705458908209, w1=13.556502440411624\n",
      "SubGD iter. 248/499: loss=4.446934381261146, w0=73.22691461707649, w1=13.556561537856144\n",
      "SubGD iter. 249/499: loss=4.446934369046919, w0=73.22691461707649, w1=13.556344829961382\n",
      "SubGD iter. 250/499: loss=4.446934394391206, w0=73.22691461707649, w1=13.556648334768354\n",
      "SubGD iter. 251/499: loss=4.446934395917743, w0=73.22691461707649, w1=13.556431626873593\n",
      "SubGD iter. 252/499: loss=4.44693435925077, w0=73.22677464507089, w1=13.556490724318113\n",
      "SubGD iter. 253/499: loss=4.446934373920315, w0=73.22705458908209, w1=13.556497276003574\n",
      "SubGD iter. 254/499: loss=4.446934381697152, w0=73.22691461707649, w1=13.556556373448094\n",
      "SubGD iter. 255/499: loss=4.446934367448107, w0=73.22691461707649, w1=13.556339665553333\n",
      "SubGD iter. 256/499: loss=4.446934396630382, w0=73.22691461707649, w1=13.556643170360305\n",
      "SubGD iter. 257/499: loss=4.44693439431893, w0=73.22691461707649, w1=13.556426462465543\n",
      "SubGD iter. 258/499: loss=4.446934359686776, w0=73.22677464507089, w1=13.556485559910064\n",
      "SubGD iter. 259/499: loss=4.44693437396865, w0=73.22705458908209, w1=13.556492111595524\n",
      "SubGD iter. 260/499: loss=4.446934382133156, w0=73.22691461707649, w1=13.556551209040045\n",
      "SubGD iter. 261/499: loss=4.4469343658492955, w0=73.22691461707649, w1=13.556334501145283\n",
      "SubGD iter. 262/499: loss=4.446934398869557, w0=73.22691461707649, w1=13.556638005952255\n",
      "SubGD iter. 263/499: loss=4.446934392720118, w0=73.22691461707649, w1=13.556421298057494\n",
      "SubGD iter. 264/499: loss=4.446934361236298, w0=73.22691461707649, w1=13.556724802864466\n",
      "SubGD iter. 265/499: loss=4.446934420608046, w0=73.22705458908209, w1=13.556486947187476\n",
      "SubGD iter. 266/499: loss=4.446934382569161, w0=73.22691461707649, w1=13.556546044631997\n",
      "SubGD iter. 267/499: loss=4.446934364250484, w0=73.22691461707649, w1=13.556329336737235\n",
      "SubGD iter. 268/499: loss=4.446934401108731, w0=73.22691461707649, w1=13.556632841544207\n",
      "SubGD iter. 269/499: loss=4.4469343911213075, w0=73.22691461707649, w1=13.556416133649446\n",
      "SubGD iter. 270/499: loss=4.446934363475474, w0=73.22691461707649, w1=13.556719638456418\n",
      "SubGD iter. 271/499: loss=4.446934418853212, w0=73.22705458908209, w1=13.556481782779429\n",
      "SubGD iter. 272/499: loss=4.446934383005166, w0=73.22691461707649, w1=13.556540880223949\n",
      "SubGD iter. 273/499: loss=4.446934362651673, w0=73.22691461707649, w1=13.556324172329187\n",
      "SubGD iter. 274/499: loss=4.446934403347907, w0=73.22691461707649, w1=13.55662767713616\n",
      "SubGD iter. 275/499: loss=4.446934389522497, w0=73.22691461707649, w1=13.556410969241398\n",
      "SubGD iter. 276/499: loss=4.446934365714649, w0=73.22691461707649, w1=13.55671447404837\n",
      "SubGD iter. 277/499: loss=4.446934417098378, w0=73.22705458908209, w1=13.55647661837138\n",
      "SubGD iter. 278/499: loss=4.44693438344117, w0=73.22691461707649, w1=13.556535715815901\n",
      "SubGD iter. 279/499: loss=4.446934361052862, w0=73.22691461707649, w1=13.55631900792114\n",
      "SubGD iter. 280/499: loss=4.446934405587082, w0=73.22691461707649, w1=13.556622512728111\n",
      "SubGD iter. 281/499: loss=4.446934387923685, w0=73.22691461707649, w1=13.55640580483335\n",
      "SubGD iter. 282/499: loss=4.4469343679538245, w0=73.22691461707649, w1=13.556709309640322\n",
      "SubGD iter. 283/499: loss=4.446934415343544, w0=73.22705458908209, w1=13.556471453963333\n",
      "SubGD iter. 284/499: loss=4.446934383877175, w0=73.22691461707649, w1=13.556530551407853\n",
      "SubGD iter. 285/499: loss=4.44693435945405, w0=73.22691461707649, w1=13.556313843513092\n",
      "SubGD iter. 286/499: loss=4.446934407826257, w0=73.22691461707649, w1=13.556617348320064\n",
      "SubGD iter. 287/499: loss=4.446934386324873, w0=73.22691461707649, w1=13.556400640425302\n",
      "SubGD iter. 288/499: loss=4.4469343701929995, w0=73.22691461707649, w1=13.556704145232274\n",
      "SubGD iter. 289/499: loss=4.4469344135887106, w0=73.22705458908209, w1=13.556466289555285\n",
      "SubGD iter. 290/499: loss=4.44693438431318, w0=73.22691461707649, w1=13.556525386999805\n",
      "SubGD iter. 291/499: loss=4.446934357855239, w0=73.22691461707649, w1=13.556308679105044\n",
      "SubGD iter. 292/499: loss=4.446934410065433, w0=73.22691461707649, w1=13.556612183912016\n",
      "SubGD iter. 293/499: loss=4.446934384726061, w0=73.22691461707649, w1=13.556395476017254\n",
      "SubGD iter. 294/499: loss=4.4469343724321755, w0=73.22691461707649, w1=13.556698980824226\n",
      "SubGD iter. 295/499: loss=4.446934411833876, w0=73.22705458908209, w1=13.556461125147237\n",
      "SubGD iter. 296/499: loss=4.446934384749184, w0=73.22691461707649, w1=13.556520222591757\n",
      "SubGD iter. 297/499: loss=4.446934356256428, w0=73.22691461707649, w1=13.556303514696996\n",
      "SubGD iter. 298/499: loss=4.446934412304608, w0=73.22691461707649, w1=13.556607019503968\n",
      "SubGD iter. 299/499: loss=4.4469343831272505, w0=73.22691461707649, w1=13.556390311609206\n",
      "SubGD iter. 300/499: loss=4.44693437467135, w0=73.22691461707649, w1=13.556693816416178\n",
      "SubGD iter. 301/499: loss=4.446934410079042, w0=73.22705458908209, w1=13.55645596073919\n",
      "SubGD iter. 302/499: loss=4.446934385185189, w0=73.22691461707649, w1=13.55651505818371\n",
      "SubGD iter. 303/499: loss=4.446934354657616, w0=73.22691461707649, w1=13.556298350288948\n",
      "SubGD iter. 304/499: loss=4.446934414543783, w0=73.22691461707649, w1=13.55660185509592\n",
      "SubGD iter. 305/499: loss=4.446934381528439, w0=73.22691461707649, w1=13.556385147201159\n",
      "SubGD iter. 306/499: loss=4.446934376910526, w0=73.22691461707649, w1=13.55668865200813\n",
      "SubGD iter. 307/499: loss=4.446934408399262, w0=73.22691461707649, w1=13.556471944113369\n",
      "SubGD iter. 308/499: loss=4.446934355846991, w0=73.22677464507089, w1=13.55653104155789\n",
      "SubGD iter. 309/499: loss=4.446934382757954, w0=73.22691461707649, w1=13.5562931858809\n",
      "SubGD iter. 310/499: loss=4.446934416782958, w0=73.22691461707649, w1=13.556596690687872\n",
      "SubGD iter. 311/499: loss=4.446934379929627, w0=73.22691461707649, w1=13.55637998279311\n",
      "SubGD iter. 312/499: loss=4.446934379149702, w0=73.22691461707649, w1=13.556683487600083\n",
      "SubGD iter. 313/499: loss=4.44693440680045, w0=73.22691461707649, w1=13.556466779705321\n",
      "SubGD iter. 314/499: loss=4.446934356282995, w0=73.22677464507089, w1=13.556525877149841\n",
      "SubGD iter. 315/499: loss=4.446934381003121, w0=73.22691461707649, w1=13.556288021472852\n",
      "SubGD iter. 316/499: loss=4.446934419022134, w0=73.22691461707649, w1=13.556591526279824\n",
      "SubGD iter. 317/499: loss=4.446934378330815, w0=73.22691461707649, w1=13.556374818385063\n",
      "SubGD iter. 318/499: loss=4.446934381388876, w0=73.22691461707649, w1=13.556678323192035\n",
      "SubGD iter. 319/499: loss=4.446934405201639, w0=73.22691461707649, w1=13.556461615297273\n",
      "SubGD iter. 320/499: loss=4.446934356719001, w0=73.22677464507089, w1=13.556520712741793\n",
      "SubGD iter. 321/499: loss=4.446934379248286, w0=73.22691461707649, w1=13.556282857064804\n",
      "SubGD iter. 322/499: loss=4.446934421261308, w0=73.22691461707649, w1=13.556586361871776\n",
      "SubGD iter. 323/499: loss=4.446934376732004, w0=73.22691461707649, w1=13.556369653977015\n",
      "SubGD iter. 324/499: loss=4.44693438362805, w0=73.22691461707649, w1=13.556673158783987\n",
      "SubGD iter. 325/499: loss=4.446934403602828, w0=73.22691461707649, w1=13.556456450889225\n",
      "SubGD iter. 326/499: loss=4.446934357155005, w0=73.22677464507089, w1=13.556515548333746\n",
      "SubGD iter. 327/499: loss=4.446934377493453, w0=73.22691461707649, w1=13.556277692656757\n",
      "SubGD iter. 328/499: loss=4.446934423500483, w0=73.22691461707649, w1=13.556581197463728\n",
      "SubGD iter. 329/499: loss=4.446934375133193, w0=73.22691461707649, w1=13.556364489568967\n",
      "SubGD iter. 330/499: loss=4.446934385867227, w0=73.22691461707649, w1=13.556667994375939\n",
      "SubGD iter. 331/499: loss=4.446934402004016, w0=73.22691461707649, w1=13.556451286481177\n",
      "SubGD iter. 332/499: loss=4.44693435759101, w0=73.22677464507089, w1=13.556510383925698\n",
      "SubGD iter. 333/499: loss=4.446934375738619, w0=73.22691461707649, w1=13.556272528248709\n",
      "SubGD iter. 334/499: loss=4.44693442573966, w0=73.22691461707649, w1=13.55657603305568\n",
      "SubGD iter. 335/499: loss=4.446934373534383, w0=73.22691461707649, w1=13.55635932516092\n",
      "SubGD iter. 336/499: loss=4.446934388106402, w0=73.22691461707649, w1=13.556662829967891\n",
      "SubGD iter. 337/499: loss=4.446934400405206, w0=73.22691461707649, w1=13.55644612207313\n",
      "SubGD iter. 338/499: loss=4.446934358027014, w0=73.22677464507089, w1=13.55650521951765\n",
      "SubGD iter. 339/499: loss=4.446934373983784, w0=73.22691461707649, w1=13.55626736384066\n",
      "SubGD iter. 340/499: loss=4.446934427978834, w0=73.22691461707649, w1=13.556570868647633\n",
      "SubGD iter. 341/499: loss=4.44693437193557, w0=73.22691461707649, w1=13.556354160752871\n",
      "SubGD iter. 342/499: loss=4.446934390345577, w0=73.22691461707649, w1=13.556657665559843\n",
      "SubGD iter. 343/499: loss=4.446934398806393, w0=73.22691461707649, w1=13.556440957665082\n",
      "SubGD iter. 344/499: loss=4.446934358463019, w0=73.22677464507089, w1=13.556500055109602\n",
      "SubGD iter. 345/499: loss=4.446934373832982, w0=73.22705458908209, w1=13.556506606795063\n",
      "SubGD iter. 346/499: loss=4.4469343809094, w0=73.22691461707649, w1=13.556565704239583\n",
      "SubGD iter. 347/499: loss=4.446934370336758, w0=73.22691461707649, w1=13.556348996344822\n",
      "SubGD iter. 348/499: loss=4.446934392584752, w0=73.22691461707649, w1=13.556652501151794\n",
      "SubGD iter. 349/499: loss=4.446934397207582, w0=73.22691461707649, w1=13.556435793257032\n",
      "SubGD iter. 350/499: loss=4.446934358899024, w0=73.22677464507089, w1=13.556494890701552\n",
      "SubGD iter. 351/499: loss=4.4469343738813185, w0=73.22705458908209, w1=13.556501442387013\n",
      "SubGD iter. 352/499: loss=4.446934381345405, w0=73.22691461707649, w1=13.556560539831533\n",
      "SubGD iter. 353/499: loss=4.4469343687379475, w0=73.22691461707649, w1=13.556343831936772\n",
      "SubGD iter. 354/499: loss=4.446934394823928, w0=73.22691461707649, w1=13.556647336743744\n",
      "SubGD iter. 355/499: loss=4.44693439560877, w0=73.22691461707649, w1=13.556430628848982\n",
      "SubGD iter. 356/499: loss=4.446934359335028, w0=73.22677464507089, w1=13.556489726293503\n",
      "SubGD iter. 357/499: loss=4.446934373929655, w0=73.22705458908209, w1=13.556496277978964\n",
      "SubGD iter. 358/499: loss=4.446934381781409, w0=73.22691461707649, w1=13.556555375423484\n",
      "SubGD iter. 359/499: loss=4.446934367139136, w0=73.22691461707649, w1=13.556338667528722\n",
      "SubGD iter. 360/499: loss=4.446934397063102, w0=73.22691461707649, w1=13.556642172335694\n",
      "SubGD iter. 361/499: loss=4.446934394009959, w0=73.22691461707649, w1=13.556425464440933\n",
      "SubGD iter. 362/499: loss=4.446934359771033, w0=73.22677464507089, w1=13.556484561885453\n",
      "SubGD iter. 363/499: loss=4.446934373977992, w0=73.22705458908209, w1=13.556491113570914\n",
      "SubGD iter. 364/499: loss=4.446934382217415, w0=73.22691461707649, w1=13.556550211015434\n",
      "SubGD iter. 365/499: loss=4.446934365540325, w0=73.22691461707649, w1=13.556333503120673\n",
      "SubGD iter. 366/499: loss=4.446934399302278, w0=73.22691461707649, w1=13.556637007927645\n",
      "SubGD iter. 367/499: loss=4.446934392411148, w0=73.22691461707649, w1=13.556420300032883\n",
      "SubGD iter. 368/499: loss=4.446934361669021, w0=73.22691461707649, w1=13.556723804839855\n",
      "SubGD iter. 369/499: loss=4.446934420268924, w0=73.22705458908209, w1=13.556485949162866\n",
      "SubGD iter. 370/499: loss=4.446934382653419, w0=73.22691461707649, w1=13.556545046607386\n",
      "SubGD iter. 371/499: loss=4.446934363941514, w0=73.22691461707649, w1=13.556328338712625\n",
      "SubGD iter. 372/499: loss=4.446934401541453, w0=73.22691461707649, w1=13.556631843519597\n",
      "SubGD iter. 373/499: loss=4.446934390812337, w0=73.22691461707649, w1=13.556415135624835\n",
      "SubGD iter. 374/499: loss=4.446934363908197, w0=73.22691461707649, w1=13.556718640431807\n",
      "SubGD iter. 375/499: loss=4.44693441851409, w0=73.22705458908209, w1=13.556480784754818\n",
      "SubGD iter. 376/499: loss=4.446934383089424, w0=73.22691461707649, w1=13.556539882199338\n",
      "SubGD iter. 377/499: loss=4.446934362342702, w0=73.22691461707649, w1=13.556323174304577\n",
      "SubGD iter. 378/499: loss=4.446934403780629, w0=73.22691461707649, w1=13.556626679111549\n",
      "SubGD iter. 379/499: loss=4.446934389213525, w0=73.22691461707649, w1=13.556409971216787\n",
      "SubGD iter. 380/499: loss=4.446934366147371, w0=73.22691461707649, w1=13.55671347602376\n",
      "SubGD iter. 381/499: loss=4.446934416759255, w0=73.22705458908209, w1=13.55647562034677\n",
      "SubGD iter. 382/499: loss=4.446934383525429, w0=73.22691461707649, w1=13.55653471779129\n",
      "SubGD iter. 383/499: loss=4.44693436074389, w0=73.22691461707649, w1=13.556318009896529\n",
      "SubGD iter. 384/499: loss=4.446934406019804, w0=73.22691461707649, w1=13.556621514703501\n",
      "SubGD iter. 385/499: loss=4.446934387614713, w0=73.22691461707649, w1=13.55640480680874\n",
      "SubGD iter. 386/499: loss=4.446934368386547, w0=73.22691461707649, w1=13.556708311615711\n",
      "SubGD iter. 387/499: loss=4.446934415004422, w0=73.22705458908209, w1=13.556470455938722\n",
      "SubGD iter. 388/499: loss=4.446934383961433, w0=73.22691461707649, w1=13.556529553383243\n",
      "SubGD iter. 389/499: loss=4.44693435914508, w0=73.22691461707649, w1=13.556312845488481\n",
      "SubGD iter. 390/499: loss=4.446934408258979, w0=73.22691461707649, w1=13.556616350295453\n",
      "SubGD iter. 391/499: loss=4.4469343860159025, w0=73.22691461707649, w1=13.556399642400692\n",
      "SubGD iter. 392/499: loss=4.446934370625721, w0=73.22691461707649, w1=13.556703147207664\n",
      "SubGD iter. 393/499: loss=4.446934413249587, w0=73.22705458908209, w1=13.556465291530674\n",
      "SubGD iter. 394/499: loss=4.446934384397438, w0=73.22691461707649, w1=13.556524388975195\n",
      "SubGD iter. 395/499: loss=4.446934357546267, w0=73.22691461707649, w1=13.556307681080433\n",
      "SubGD iter. 396/499: loss=4.446934410498153, w0=73.22691461707649, w1=13.556611185887405\n",
      "SubGD iter. 397/499: loss=4.446934384417091, w0=73.22691461707649, w1=13.556394477992644\n",
      "SubGD iter. 398/499: loss=4.446934372864897, w0=73.22691461707649, w1=13.556697982799616\n",
      "SubGD iter. 399/499: loss=4.4469344114947535, w0=73.22705458908209, w1=13.556460127122627\n",
      "SubGD iter. 400/499: loss=4.446934384833443, w0=73.22691461707649, w1=13.556519224567147\n",
      "SubGD iter. 401/499: loss=4.446934355947456, w0=73.22691461707649, w1=13.556302516672385\n",
      "SubGD iter. 402/499: loss=4.446934412737329, w0=73.22691461707649, w1=13.556606021479357\n",
      "SubGD iter. 403/499: loss=4.44693438281828, w0=73.22691461707649, w1=13.556389313584596\n",
      "SubGD iter. 404/499: loss=4.446934375104073, w0=73.22691461707649, w1=13.556692818391568\n",
      "SubGD iter. 405/499: loss=4.44693440973992, w0=73.22705458908209, w1=13.556454962714579\n",
      "SubGD iter. 406/499: loss=4.446934385269446, w0=73.22691461707649, w1=13.556514060159099\n",
      "SubGD iter. 407/499: loss=4.446934354348644, w0=73.22691461707649, w1=13.556297352264338\n",
      "SubGD iter. 408/499: loss=4.446934414976504, w0=73.22691461707649, w1=13.55660085707131\n",
      "SubGD iter. 409/499: loss=4.446934381219467, w0=73.22691461707649, w1=13.556384149176548\n",
      "SubGD iter. 410/499: loss=4.446934377343247, w0=73.22691461707649, w1=13.55668765398352\n",
      "SubGD iter. 411/499: loss=4.446934408090291, w0=73.22691461707649, w1=13.556470946088758\n",
      "SubGD iter. 412/499: loss=4.4469343559312495, w0=73.22677464507089, w1=13.556530043533279\n",
      "SubGD iter. 413/499: loss=4.446934382418831, w0=73.22691461707649, w1=13.55629218785629\n",
      "SubGD iter. 414/499: loss=4.4469344172156795, w0=73.22691461707649, w1=13.556595692663262\n",
      "SubGD iter. 415/499: loss=4.446934379620656, w0=73.22691461707649, w1=13.5563789847685\n",
      "SubGD iter. 416/499: loss=4.446934379582423, w0=73.22691461707649, w1=13.556682489575472\n",
      "SubGD iter. 417/499: loss=4.44693440649148, w0=73.22691461707649, w1=13.55646578168071\n",
      "SubGD iter. 418/499: loss=4.446934356367254, w0=73.22677464507089, w1=13.55652487912523\n",
      "SubGD iter. 419/499: loss=4.446934380663998, w0=73.22691461707649, w1=13.556287023448242\n",
      "SubGD iter. 420/499: loss=4.4469344194548555, w0=73.22691461707649, w1=13.556590528255214\n",
      "SubGD iter. 421/499: loss=4.446934378021845, w0=73.22691461707649, w1=13.556373820360452\n",
      "SubGD iter. 422/499: loss=4.446934381821598, w0=73.22691461707649, w1=13.556677325167424\n",
      "SubGD iter. 423/499: loss=4.446934404892668, w0=73.22691461707649, w1=13.556460617272663\n",
      "SubGD iter. 424/499: loss=4.446934356803259, w0=73.22677464507089, w1=13.556519714717183\n",
      "SubGD iter. 425/499: loss=4.446934378909163, w0=73.22691461707649, w1=13.556281859040194\n",
      "SubGD iter. 426/499: loss=4.446934421694031, w0=73.22691461707649, w1=13.556585363847166\n",
      "SubGD iter. 427/499: loss=4.446934376423033, w0=73.22691461707649, w1=13.556368655952404\n",
      "SubGD iter. 428/499: loss=4.446934384060772, w0=73.22691461707649, w1=13.556672160759376\n",
      "SubGD iter. 429/499: loss=4.446934403293857, w0=73.22691461707649, w1=13.556455452864615\n",
      "SubGD iter. 430/499: loss=4.446934357239265, w0=73.22677464507089, w1=13.556514550309135\n",
      "SubGD iter. 431/499: loss=4.44693437715433, w0=73.22691461707649, w1=13.556276694632146\n",
      "SubGD iter. 432/499: loss=4.446934423933205, w0=73.22691461707649, w1=13.556580199439118\n",
      "SubGD iter. 433/499: loss=4.446934374824222, w0=73.22691461707649, w1=13.556363491544356\n",
      "SubGD iter. 434/499: loss=4.446934386299948, w0=73.22691461707649, w1=13.556666996351328\n",
      "SubGD iter. 435/499: loss=4.446934401695045, w0=73.22691461707649, w1=13.556450288456567\n",
      "SubGD iter. 436/499: loss=4.446934357675268, w0=73.22677464507089, w1=13.556509385901087\n",
      "SubGD iter. 437/499: loss=4.446934375399496, w0=73.22691461707649, w1=13.556271530224098\n",
      "SubGD iter. 438/499: loss=4.4469344261723815, w0=73.22691461707649, w1=13.55657503503107\n",
      "SubGD iter. 439/499: loss=4.446934373225411, w0=73.22691461707649, w1=13.556358327136309\n",
      "SubGD iter. 440/499: loss=4.446934388539124, w0=73.22691461707649, w1=13.55666183194328\n",
      "SubGD iter. 441/499: loss=4.446934400096234, w0=73.22691461707649, w1=13.556445124048519\n",
      "SubGD iter. 442/499: loss=4.446934358111273, w0=73.22677464507089, w1=13.55650422149304\n",
      "SubGD iter. 443/499: loss=4.446934373793987, w0=73.22705458908209, w1=13.5565107731785\n",
      "SubGD iter. 444/499: loss=4.4469343805576536, w0=73.22691461707649, w1=13.55656987062302\n",
      "SubGD iter. 445/499: loss=4.4469343716265985, w0=73.22691461707649, w1=13.556353162728259\n",
      "SubGD iter. 446/499: loss=4.446934390778299, w0=73.22691461707649, w1=13.556656667535231\n",
      "SubGD iter. 447/499: loss=4.446934398497422, w0=73.22691461707649, w1=13.55643995964047\n",
      "SubGD iter. 448/499: loss=4.446934358547277, w0=73.22677464507089, w1=13.55649905708499\n",
      "SubGD iter. 449/499: loss=4.446934373842323, w0=73.22705458908209, w1=13.55650560877045\n",
      "SubGD iter. 450/499: loss=4.446934380993658, w0=73.22691461707649, w1=13.55656470621497\n",
      "SubGD iter. 451/499: loss=4.446934370027788, w0=73.22691461707649, w1=13.55634799832021\n",
      "SubGD iter. 452/499: loss=4.446934393017473, w0=73.22691461707649, w1=13.556651503127181\n",
      "SubGD iter. 453/499: loss=4.446934396898611, w0=73.22691461707649, w1=13.55643479523242\n",
      "SubGD iter. 454/499: loss=4.446934358983281, w0=73.22677464507089, w1=13.55649389267694\n",
      "SubGD iter. 455/499: loss=4.44693437389066, w0=73.22705458908209, w1=13.5565004443624\n",
      "SubGD iter. 456/499: loss=4.446934381429663, w0=73.22691461707649, w1=13.556559541806921\n",
      "SubGD iter. 457/499: loss=4.446934368428976, w0=73.22691461707649, w1=13.55634283391216\n",
      "SubGD iter. 458/499: loss=4.446934395256649, w0=73.22691461707649, w1=13.556646338719132\n",
      "SubGD iter. 459/499: loss=4.4469343952998, w0=73.22691461707649, w1=13.55642963082437\n",
      "SubGD iter. 460/499: loss=4.446934359419287, w0=73.22677464507089, w1=13.55648872826889\n",
      "SubGD iter. 461/499: loss=4.446934373938996, w0=73.22705458908209, w1=13.556495279954351\n",
      "SubGD iter. 462/499: loss=4.446934381865668, w0=73.22691461707649, w1=13.556554377398871\n",
      "SubGD iter. 463/499: loss=4.446934366830165, w0=73.22691461707649, w1=13.55633766950411\n",
      "SubGD iter. 464/499: loss=4.446934397495824, w0=73.22691461707649, w1=13.556641174311082\n",
      "SubGD iter. 465/499: loss=4.446934393700988, w0=73.22691461707649, w1=13.55642446641632\n",
      "SubGD iter. 466/499: loss=4.446934359862568, w0=73.22691461707649, w1=13.556727971223292\n",
      "SubGD iter. 467/499: loss=4.446934421684635, w0=73.22705458908209, w1=13.556490115546303\n",
      "SubGD iter. 468/499: loss=4.446934382301672, w0=73.22691461707649, w1=13.556549212990824\n",
      "SubGD iter. 469/499: loss=4.446934365231353, w0=73.22691461707649, w1=13.556332505096062\n",
      "SubGD iter. 470/499: loss=4.4469343997349995, w0=73.22691461707649, w1=13.556636009903034\n",
      "SubGD iter. 471/499: loss=4.446934392102177, w0=73.22691461707649, w1=13.556419302008273\n",
      "SubGD iter. 472/499: loss=4.446934362101743, w0=73.22691461707649, w1=13.556722806815245\n",
      "SubGD iter. 473/499: loss=4.4469344199298, w0=73.22705458908209, w1=13.556484951138255\n",
      "SubGD iter. 474/499: loss=4.446934382737678, w0=73.22691461707649, w1=13.556544048582776\n",
      "SubGD iter. 475/499: loss=4.4469343636325425, w0=73.22691461707649, w1=13.556327340688014\n",
      "SubGD iter. 476/499: loss=4.446934401974175, w0=73.22691461707649, w1=13.556630845494986\n",
      "SubGD iter. 477/499: loss=4.446934390503366, w0=73.22691461707649, w1=13.556414137600225\n",
      "SubGD iter. 478/499: loss=4.446934364340917, w0=73.22691461707649, w1=13.556717642407197\n",
      "SubGD iter. 479/499: loss=4.446934418174968, w0=73.22705458908209, w1=13.556479786730208\n",
      "SubGD iter. 480/499: loss=4.446934383173683, w0=73.22691461707649, w1=13.556538884174728\n",
      "SubGD iter. 481/499: loss=4.446934362033731, w0=73.22691461707649, w1=13.556322176279966\n",
      "SubGD iter. 482/499: loss=4.4469344042133505, w0=73.22691461707649, w1=13.556625681086938\n",
      "SubGD iter. 483/499: loss=4.4469343889045545, w0=73.22691461707649, w1=13.556408973192177\n",
      "SubGD iter. 484/499: loss=4.446934366580092, w0=73.22691461707649, w1=13.556712477999149\n",
      "SubGD iter. 485/499: loss=4.446934416420133, w0=73.22705458908209, w1=13.55647462232216\n",
      "SubGD iter. 486/499: loss=4.446934383609687, w0=73.22691461707649, w1=13.55653371976668\n",
      "SubGD iter. 487/499: loss=4.446934360434919, w0=73.22691461707649, w1=13.556317011871919\n",
      "SubGD iter. 488/499: loss=4.446934406452526, w0=73.22691461707649, w1=13.55662051667889\n",
      "SubGD iter. 489/499: loss=4.446934387305742, w0=73.22691461707649, w1=13.556403808784129\n",
      "SubGD iter. 490/499: loss=4.446934368819268, w0=73.22691461707649, w1=13.556707313591101\n",
      "SubGD iter. 491/499: loss=4.446934414665299, w0=73.22705458908209, w1=13.556469457914112\n",
      "SubGD iter. 492/499: loss=4.446934384045692, w0=73.22691461707649, w1=13.556528555358632\n",
      "SubGD iter. 493/499: loss=4.446934358836108, w0=73.22691461707649, w1=13.55631184746387\n",
      "SubGD iter. 494/499: loss=4.446934408691701, w0=73.22691461707649, w1=13.556615352270843\n",
      "SubGD iter. 495/499: loss=4.446934385706931, w0=73.22691461707649, w1=13.556398644376081\n",
      "SubGD iter. 496/499: loss=4.446934371058443, w0=73.22691461707649, w1=13.556702149183053\n",
      "SubGD iter. 497/499: loss=4.4469344129104655, w0=73.22705458908209, w1=13.556464293506064\n",
      "SubGD iter. 498/499: loss=4.446934384481695, w0=73.22691461707649, w1=13.556523390950584\n",
      "SubGD iter. 499/499: loss=4.446934357237297, w0=73.22691461707649, w1=13.556306683055823\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf69b8ae4944f779799186b9f230b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subgd_losses,\n",
    "        subgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Compute a stochastic subgradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: implement stochastic subgradient descent.\n",
    "        # ***************************************************\n",
    "\n",
    "\n",
    "        stochastic_subgrad = compute_subgradient_mae(y, tx, w)\n",
    "        w = w - gamma * stochastic_subgrad\n",
    "        loss= compute_loss(y,tx,w)\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "\n",
    "        print(\n",
    "            \"SubSGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubSGD iter. 0/499: loss=2741.9963749472076, w0=0.7, w1=-1.2332555381718993e-16\n",
      "SubSGD iter. 1/499: loss=2691.4194249753755, w0=1.4, w1=-2.4665110763437986e-16\n",
      "SubSGD iter. 2/499: loss=2641.3324750035445, w0=2.0999999999999996, w1=-3.699766614515698e-16\n",
      "SubSGD iter. 3/499: loss=2591.7355250317128, w0=2.8, w1=-4.933022152687597e-16\n",
      "SubSGD iter. 4/499: loss=2542.6285750598813, w0=3.5, w1=-6.166277690859497e-16\n",
      "SubSGD iter. 5/499: loss=2494.0116250880487, w0=4.2, w1=-7.399533229031396e-16\n",
      "SubSGD iter. 6/499: loss=2445.8846751162173, w0=4.9, w1=-8.632788767203295e-16\n",
      "SubSGD iter. 7/499: loss=2398.2477251443856, w0=5.6000000000000005, w1=-9.866044305375195e-16\n",
      "SubSGD iter. 8/499: loss=2351.100775172554, w0=6.300000000000001, w1=-1.1099299843547093e-15\n",
      "SubSGD iter. 9/499: loss=2304.4438252007226, w0=7.000000000000001, w1=-1.2332555381718991e-15\n",
      "SubSGD iter. 10/499: loss=2258.2768752288907, w0=7.700000000000001, w1=-1.356581091989089e-15\n",
      "SubSGD iter. 11/499: loss=2212.5999252570587, w0=8.4, w1=-1.4799066458062788e-15\n",
      "SubSGD iter. 12/499: loss=2167.4129752852277, w0=9.1, w1=-1.6032321996234686e-15\n",
      "SubSGD iter. 13/499: loss=2122.7160253133957, w0=9.799999999999999, w1=-1.7265577534406585e-15\n",
      "SubSGD iter. 14/499: loss=2078.509075341564, w0=10.499999999999998, w1=-1.8498833072578483e-15\n",
      "SubSGD iter. 15/499: loss=2034.7921253697325, w0=11.199999999999998, w1=-1.973208861075038e-15\n",
      "SubSGD iter. 16/499: loss=1991.5651753979012, w0=11.899999999999997, w1=-2.096534414892228e-15\n",
      "SubSGD iter. 17/499: loss=1948.8282254260694, w0=12.599999999999996, w1=-2.2198599687094178e-15\n",
      "SubSGD iter. 18/499: loss=1906.5812754542376, w0=13.299999999999995, w1=-2.3431855225266076e-15\n",
      "SubSGD iter. 19/499: loss=1864.8243254824058, w0=13.999999999999995, w1=-2.4665110763437975e-15\n",
      "SubSGD iter. 20/499: loss=1823.5573755105747, w0=14.699999999999994, w1=-2.5898366301609873e-15\n",
      "SubSGD iter. 21/499: loss=1782.7804255387427, w0=15.399999999999993, w1=-2.713162183978177e-15\n",
      "SubSGD iter. 22/499: loss=1742.493475566911, w0=16.099999999999994, w1=-2.836487737795367e-15\n",
      "SubSGD iter. 23/499: loss=1702.6965255950793, w0=16.799999999999994, w1=-2.9598132916125568e-15\n",
      "SubSGD iter. 24/499: loss=1663.3895756232478, w0=17.499999999999993, w1=-3.0831388454297466e-15\n",
      "SubSGD iter. 25/499: loss=1624.5726256514158, w0=18.199999999999992, w1=-3.2064643992469365e-15\n",
      "SubSGD iter. 26/499: loss=1586.245675679584, w0=18.89999999999999, w1=-3.3297899530641263e-15\n",
      "SubSGD iter. 27/499: loss=1548.4087257077526, w0=19.59999999999999, w1=-3.453115506881316e-15\n",
      "SubSGD iter. 28/499: loss=1511.0617757359212, w0=20.29999999999999, w1=-3.576441060698506e-15\n",
      "SubSGD iter. 29/499: loss=1474.2048257640893, w0=20.99999999999999, w1=-3.6997666145156966e-15\n",
      "SubSGD iter. 30/499: loss=1437.8378757922578, w0=21.69999999999999, w1=-3.823092168332887e-15\n",
      "SubSGD iter. 31/499: loss=1401.9609258204262, w0=22.399999999999988, w1=-3.946417722150077e-15\n",
      "SubSGD iter. 32/499: loss=1366.5739758485945, w0=23.099999999999987, w1=-4.069743275967267e-15\n",
      "SubSGD iter. 33/499: loss=1331.6770258767629, w0=23.799999999999986, w1=-4.1930688297844575e-15\n",
      "SubSGD iter. 34/499: loss=1297.2700759049312, w0=24.499999999999986, w1=-4.316394383601648e-15\n",
      "SubSGD iter. 35/499: loss=1263.3531259330996, w0=25.199999999999985, w1=-4.439719937418838e-15\n",
      "SubSGD iter. 36/499: loss=1229.926175961268, w0=25.899999999999984, w1=-4.563045491236028e-15\n",
      "SubSGD iter. 37/499: loss=1196.9892259894361, w0=26.599999999999984, w1=-4.6863710450532184e-15\n",
      "SubSGD iter. 38/499: loss=1164.5422760176043, w0=27.299999999999983, w1=-4.809696598870409e-15\n",
      "SubSGD iter. 39/499: loss=1132.5853260457727, w0=27.999999999999982, w1=-4.933022152687599e-15\n",
      "SubSGD iter. 40/499: loss=1101.1183760739414, w0=28.69999999999998, w1=-5.056347706504789e-15\n",
      "SubSGD iter. 41/499: loss=1070.1414261021096, w0=29.39999999999998, w1=-5.179673260321979e-15\n",
      "SubSGD iter. 42/499: loss=1039.6546429872506, w0=30.09986002799438, w1=0.0004390332530533584\n",
      "SubSGD iter. 43/499: loss=1009.6576641239259, w0=30.799720055988782, w1=0.0008780665061118965\n",
      "SubSGD iter. 44/499: loss=980.1504895121358, w0=31.499580083983183, w1=0.0013170997591704346\n",
      "SubSGD iter. 45/499: loss=951.1336756301051, w0=32.19930013997199, w1=0.0021441866048852194\n",
      "SubSGD iter. 46/499: loss=922.6064705889, w0=32.899020195960794, w1=0.0029712734506000043\n",
      "SubSGD iter. 47/499: loss=894.5687250332164, w0=33.598600279943994, w1=0.004224559476621934\n",
      "SubSGD iter. 48/499: loss=867.0214759522115, w0=34.298040391921596, w1=0.005804766748670344\n",
      "SubSGD iter. 49/499: loss=839.963445838505, w0=34.9974805038992, w1=0.007384974020718754\n",
      "SubSGD iter. 50/499: loss=813.3946346920967, w0=35.6969206158768, w1=0.008965181292767164\n",
      "SubSGD iter. 51/499: loss=787.3164649052991, w0=36.3960807838432, w1=0.011211104070244973\n",
      "SubSGD iter. 52/499: loss=761.7270232614263, w0=37.09496100779841, w1=0.014222184655636138\n",
      "SubSGD iter. 53/499: loss=736.6260175623262, w0=37.79370125974802, w1=0.017605329057828974\n",
      "SubSGD iter. 54/499: loss=712.0159419685004, w0=38.49216156768643, w1=0.021516730245136\n",
      "SubSGD iter. 55/499: loss=687.8942293194194, w0=39.190201959608046, w1=0.02646219697935598\n",
      "SubSGD iter. 56/499: loss=664.2619366371293, w0=39.88740251949607, w1=0.033348128333762495\n",
      "SubSGD iter. 57/499: loss=641.1183228897751, w0=40.5840431913617, w1=0.04141548114171521\n",
      "SubSGD iter. 58/499: loss=618.4580469431806, w0=41.28012397520493, w1=0.05097899237356002\n",
      "SubSGD iter. 59/499: loss=596.2850971816489, w0=41.97494501099777, w1=0.06329961379535383\n",
      "SubSGD iter. 60/499: loss=574.5997007284064, w0=42.667806438712226, w1=0.07978094219757825\n",
      "SubSGD iter. 61/499: loss=553.4003710010177, w0=43.3591281743651, w1=0.09929806319975969\n",
      "SubSGD iter. 62/499: loss=532.6805526250607, w0=44.04877024595078, w1=0.12242622134166117\n",
      "SubSGD iter. 63/499: loss=512.4445983218556, w0=44.73561287742448, w1=0.15100859237468173\n",
      "SubSGD iter. 64/499: loss=492.6896595284149, w0=45.41979604079181, w1=0.18456407916033185\n",
      "SubSGD iter. 65/499: loss=473.4115235122847, w0=46.100619876024766, w1=0.22448157906915986\n",
      "SubSGD iter. 66/499: loss=454.6101708252712, w0=46.77836432713455, w1=0.269732014107414\n",
      "SubSGD iter. 67/499: loss=436.28525846694055, w0=47.45232953409315, w1=0.32130192698519267\n",
      "SubSGD iter. 68/499: loss=418.44245889378203, w0=48.11985602879421, w1=0.38338978824408276\n",
      "SubSGD iter. 69/499: loss=401.06684098993435, w0=48.78248350329931, w1=0.453386602496482\n",
      "SubSGD iter. 70/499: loss=384.1438656791127, w0=49.44133173365324, w1=0.5297174602200958\n",
      "SubSGD iter. 71/499: loss=367.67621436643446, w0=50.09458108378322, w1=0.6150057665180065\n",
      "SubSGD iter. 72/499: loss=351.66511058056454, w0=50.741531693661244, w1=0.709715506684579\n",
      "SubSGD iter. 73/499: loss=336.1013552757648, w0=51.38190361927612, w1=0.8143067463296961\n",
      "SubSGD iter. 74/499: loss=320.9816761210069, w0=52.01541691661666, w1=0.9287549135079824\n",
      "SubSGD iter. 75/499: loss=306.2983620717276, w0=52.641791641671645, w1=1.0533715069904093\n",
      "SubSGD iter. 76/499: loss=292.0514020274885, w0=53.260747850429894, w1=1.1878295503598069\n",
      "SubSGD iter. 77/499: loss=278.2190023486676, w0=53.873125374924996, w1=1.3317700853243954\n",
      "SubSGD iter. 78/499: loss=264.80658530031735, w0=54.47822435512896, w1=1.4851730325164136\n",
      "SubSGD iter. 79/499: loss=251.80888940684983, w0=55.07548490301938, w1=1.6486010251013725\n",
      "SubSGD iter. 80/499: loss=239.22987430794905, w0=55.66364727054587, w1=1.8228431330769275\n",
      "SubSGD iter. 81/499: loss=227.0606558505782, w0=56.24243151369724, w1=2.0081856078826092\n",
      "SubSGD iter. 82/499: loss=215.29164663595714, w0=56.813517296540674, w1=2.2021065222377607\n",
      "SubSGD iter. 83/499: loss=203.9411605220025, w0=57.37452509498099, w1=2.405642025817045\n",
      "SubSGD iter. 84/499: loss=192.9847732757794, w0=57.92727454509097, w1=2.617432977366366\n",
      "SubSGD iter. 85/499: loss=182.4215826166934, w0=58.471205758848214, w1=2.837551090137762\n",
      "SubSGD iter. 86/499: loss=172.24064692488884, w0=59.00617876424713, w1=3.066388708143779\n",
      "SubSGD iter. 87/499: loss=162.43444343814747, w0=59.531773645270924, w1=3.3044328747838345\n",
      "SubSGD iter. 88/499: loss=153.00294963247563, w0=60.049390121975584, w1=3.5489669244691435\n",
      "SubSGD iter. 89/499: loss=143.96320647589783, w0=60.55496900619874, w1=3.8028126363236816\n",
      "SubSGD iter. 90/499: loss=135.28857061156768, w0=61.052429514097156, w1=4.062481967409632\n",
      "SubSGD iter. 91/499: loss=126.96617586264009, w0=61.54219156168764, w1=4.328013364242923\n",
      "SubSGD iter. 92/499: loss=119.00159715607971, w0=62.02299540091979, w1=4.599633379203242\n",
      "SubSGD iter. 93/499: loss=111.37879221335871, w0=62.49484103179361, w1=4.878291050974949\n",
      "SubSGD iter. 94/499: loss=104.11189944618532, w0=62.95758848230351, w1=5.1616188421531914\n",
      "SubSGD iter. 95/499: loss=97.20007927942963, w0=63.41067786442708, w1=5.449329378501437\n",
      "SubSGD iter. 96/499: loss=90.63016359697284, w0=63.85494901019793, w1=5.740885365949973\n",
      "SubSGD iter. 97/499: loss=84.39232412831484, w0=64.29110177964404, w1=6.035625156501035\n",
      "SubSGD iter. 98/499: loss=78.50644057216569, w0=64.71619676064783, w1=6.333201492316891\n",
      "SubSGD iter. 99/499: loss=72.95499785065526, w0=65.13177364527091, w1=6.632632773794741\n",
      "SubSGD iter. 100/499: loss=67.73942421704655, w0=65.53727254549086, w1=6.9327920605249576\n",
      "SubSGD iter. 101/499: loss=62.84046498016872, w0=65.9339532093581, w1=7.233414234721268\n",
      "SubSGD iter. 102/499: loss=58.25243297722141, w0=66.320275944811, w1=7.535584854277058\n",
      "SubSGD iter. 103/499: loss=53.96489105335333, w0=66.6969406118776, w1=7.838442184331338\n",
      "SubSGD iter. 104/499: loss=49.979982844712445, w0=67.06226754649067, w1=8.141614439592079\n",
      "SubSGD iter. 105/499: loss=46.27873360583439, w0=67.41891621675661, w1=8.443320496246868\n",
      "SubSGD iter. 106/499: loss=42.83892404126666, w0=67.7694061187762, w1=8.743057731565969\n",
      "SubSGD iter. 107/499: loss=39.68099550231917, w0=68.1077184563087, w1=9.04141481718868\n",
      "SubSGD iter. 108/499: loss=36.783073317712955, w0=68.43693261347727, w1=9.336737930365242\n",
      "SubSGD iter. 109/499: loss=34.13079979100406, w0=68.7583083383323, w1=9.628219259354854\n",
      "SubSGD iter. 110/499: loss=31.732456078737094, w0=69.0701659668066, w1=9.912384627099724\n",
      "SubSGD iter. 111/499: loss=29.579702850495657, w0=69.3688662267546, w1=10.191577499035187\n",
      "SubSGD iter. 112/499: loss=27.66689786046234, w0=69.65328934213153, w1=10.463672134401827\n",
      "SubSGD iter. 113/499: loss=25.970792231271243, w0=69.92679464107174, w1=10.726390556476394\n",
      "SubSGD iter. 114/499: loss=24.478739169603383, w0=70.18924215156964, w1=10.978380557628476\n",
      "SubSGD iter. 115/499: loss=23.18461587165631, w0=70.43685262947406, w1=11.219701967428096\n",
      "SubSGD iter. 116/499: loss=22.06351800777295, w0=70.67284543091377, w1=11.449165318666559\n",
      "SubSGD iter. 117/499: loss=21.1014566875189, w0=70.89652069586077, w1=11.666356516752096\n",
      "SubSGD iter. 118/499: loss=20.293441990318343, w0=71.1056388722255, w1=11.867108883130133\n",
      "SubSGD iter. 119/499: loss=19.62018043221181, w0=71.30033993201354, w1=12.051407766868662\n",
      "SubSGD iter. 120/499: loss=19.066063851894597, w0=71.48048390321931, w1=12.217845301729664\n",
      "SubSGD iter. 121/499: loss=18.612197969412776, w0=71.64621075784838, w1=12.368249551058984\n",
      "SubSGD iter. 122/499: loss=18.245218387849377, w0=71.79696060787838, w1=12.502401790610863\n",
      "SubSGD iter. 123/499: loss=17.94323578851397, w0=71.93525294941007, w1=12.626956346855325\n",
      "SubSGD iter. 124/499: loss=17.698868105697837, w0=72.06220755848825, w1=12.737690959456451\n",
      "SubSGD iter. 125/499: loss=17.504363615641655, w0=72.17670465906814, w1=12.834789566779996\n",
      "SubSGD iter. 126/499: loss=17.350132016277538, w0=72.27916416716651, w1=12.920166995931814\n",
      "SubSGD iter. 127/499: loss=17.225912079133938, w0=72.37210557888417, w1=12.996860468282232\n",
      "SubSGD iter. 128/499: loss=17.125325454022274, w0=72.4574885022995, w1=13.065076915423859\n",
      "SubSGD iter. 129/499: loss=17.045122195719575, w0=72.53475304939008, w1=13.124849343844442\n",
      "SubSGD iter. 130/499: loss=16.980982481378096, w0=72.60459908018392, w1=13.178183638705837\n",
      "SubSGD iter. 131/499: loss=16.930748133678545, w0=72.66660667866422, w1=13.224139301602635\n",
      "SubSGD iter. 132/499: loss=16.89133826388153, w0=72.72133573285339, w1=13.264864394964698\n",
      "SubSGD iter. 133/499: loss=16.859227184904885, w0=72.77186562687459, w1=13.30091509114702\n",
      "SubSGD iter. 134/499: loss=16.833470361571834, w0=72.81763647270542, w1=13.333500176263556\n",
      "SubSGD iter. 135/499: loss=16.813168426665186, w0=72.85850829834028, w1=13.361656909184125\n",
      "SubSGD iter. 136/499: loss=16.797060378473013, w0=72.89518096380719, w1=13.385470159777041\n",
      "SubSGD iter. 137/499: loss=16.78418525744035, w0=72.92821435712852, w1=13.406736705866416\n",
      "SubSGD iter. 138/499: loss=16.774034157229266, w0=72.9574685062987, w1=13.424351640528354\n",
      "SubSGD iter. 139/499: loss=16.765666437012023, w0=72.98448310337928, w1=13.439983794143533\n",
      "SubSGD iter. 140/499: loss=16.75883615947632, w0=73.00925814837028, w1=13.45411035086824\n",
      "SubSGD iter. 141/499: loss=16.753405950646563, w0=73.0310937812437, w1=13.465384196687685\n",
      "SubSGD iter. 142/499: loss=16.749278310414883, w0=73.05026994601074, w1=13.477028241909224\n",
      "SubSGD iter. 143/499: loss=16.745900538891636, w0=73.0681863627274, w1=13.488161740639182\n",
      "SubSGD iter. 144/499: loss=16.743167669056064, w0=73.08442311537688, w1=13.49771172811726\n",
      "SubSGD iter. 145/499: loss=16.741079600077228, w0=73.09856028794236, w1=13.506048564348895\n",
      "SubSGD iter. 146/499: loss=16.739375966904614, w0=73.11129774045186, w1=13.513115848283256\n",
      "SubSGD iter. 147/499: loss=16.738030434903376, w0=73.12249550089977, w1=13.5191443480512\n",
      "SubSGD iter. 148/499: loss=16.736913197950226, w0=73.1328534293141, w1=13.524593524222752\n",
      "SubSGD iter. 149/499: loss=16.735958914284094, w0=73.14279144171162, w1=13.52973999124479\n",
      "SubSGD iter. 150/499: loss=16.735108302564768, w0=73.15188962207554, w1=13.53383204216614\n",
      "SubSGD iter. 151/499: loss=16.734504569334355, w0=73.16000799840027, w1=13.537979284490284\n",
      "SubSGD iter. 152/499: loss=16.734019659524712, w0=73.16686662667462, w1=13.541214002705695\n",
      "SubSGD iter. 153/499: loss=16.73359742953228, w0=73.17274545090977, w1=13.543637004539578\n",
      "SubSGD iter. 154/499: loss=16.733263539506975, w0=73.17806438712253, w1=13.545916766781724\n",
      "SubSGD iter. 155/499: loss=16.732933430824094, w0=73.1829634073185, w1=13.547677121744794\n",
      "SubSGD iter. 156/499: loss=16.73264046604485, w0=73.18744251149766, w1=13.54919080283612\n",
      "SubSGD iter. 157/499: loss=16.7323882354714, w0=73.19136172765444, w1=13.550424348030843\n",
      "SubSGD iter. 158/499: loss=16.73206051399994, w0=73.19458108378322, w1=13.550589303562214\n",
      "SubSGD iter. 159/499: loss=16.731740916948215, w0=73.19766046790639, w1=13.550645922422449\n",
      "SubSGD iter. 160/499: loss=16.731452529698153, w0=73.20059988002396, w1=13.550749965492663\n",
      "SubSGD iter. 161/499: loss=16.731355459676827, w0=73.20297940411913, w1=13.551661450201802\n",
      "SubSGD iter. 162/499: loss=16.731270729115295, w0=73.20521895620871, w1=13.552523723725939\n",
      "SubSGD iter. 163/499: loss=16.73120804418904, w0=73.20731853629269, w1=13.553404406621754\n",
      "SubSGD iter. 164/499: loss=16.731134716980733, w0=73.20927814437107, w1=13.55410460736463\n",
      "SubSGD iter. 165/499: loss=16.731065720117332, w0=73.21123775244945, w1=13.554804808107507\n",
      "SubSGD iter. 166/499: loss=16.73095600565509, w0=73.21277744451103, w1=13.5549916568736\n",
      "SubSGD iter. 167/499: loss=16.730834907335083, w0=73.21417716456702, w1=13.555015938361008\n",
      "SubSGD iter. 168/499: loss=16.7307157688209, w0=73.215576884623, w1=13.555040219848415\n",
      "SubSGD iter. 169/499: loss=16.730609400874986, w0=73.2164167166566, w1=13.554832133791885\n",
      "SubSGD iter. 170/499: loss=16.730503781546723, w0=73.21725654869019, w1=13.554624047735356\n",
      "SubSGD iter. 171/499: loss=16.730398910836108, w0=73.21809638072378, w1=13.554415961678826\n",
      "SubSGD iter. 172/499: loss=16.730294788743148, w0=73.21893621275737, w1=13.554207875622296\n",
      "SubSGD iter. 173/499: loss=16.730247643816124, w0=73.21963607278536, w1=13.554278368545425\n",
      "SubSGD iter. 174/499: loss=16.730200993662418, w0=73.22033593281336, w1=13.554348861468554\n",
      "SubSGD iter. 175/499: loss=16.730157215876105, w0=73.22089582083575, w1=13.554362759813328\n",
      "SubSGD iter. 176/499: loss=16.730135862599308, w0=73.22131573685255, w1=13.554443486398297\n",
      "SubSGD iter. 177/499: loss=16.73011469216875, w0=73.22173565286934, w1=13.554524212983265\n",
      "SubSGD iter. 178/499: loss=16.730093704584437, w0=73.22215556888614, w1=13.554604939568234\n",
      "SubSGD iter. 179/499: loss=16.730072899846366, w0=73.22257548490293, w1=13.554685666153203\n",
      "SubSGD iter. 180/499: loss=16.730052277954538, w0=73.22299540091973, w1=13.554766392738172\n",
      "SubSGD iter. 181/499: loss=16.730031838908953, w0=73.22341531693652, w1=13.55484711932314\n",
      "SubSGD iter. 182/499: loss=16.73001158270961, w0=73.22383523295332, w1=13.554927845908109\n",
      "SubSGD iter. 183/499: loss=16.730046944748636, w0=73.22411517696452, w1=13.55528437783236\n",
      "SubSGD iter. 184/499: loss=16.73002701773012, w0=73.22453509298131, w1=13.555365104417328\n",
      "SubSGD iter. 185/499: loss=16.73000727355784, w0=73.22495500899811, w1=13.555445831002297\n",
      "SubSGD iter. 186/499: loss=16.73004200265551, w0=73.2250949810037, w1=13.555728188027041\n",
      "SubSGD iter. 187/499: loss=16.730021352135207, w0=73.2253749250149, w1=13.555734739712502\n",
      "SubSGD iter. 188/499: loss=16.730000780026476, w0=73.2256548690261, w1=13.555741291397963\n",
      "SubSGD iter. 189/499: loss=16.730035690510277, w0=73.2257948410317, w1=13.556023648422707\n",
      "SubSGD iter. 190/499: loss=16.73001523784736, w0=73.2260747850429, w1=13.556030200108168\n",
      "SubSGD iter. 191/499: loss=16.730050288683053, w0=73.2262147570485, w1=13.556312557132912\n",
      "SubSGD iter. 192/499: loss=16.730029955465948, w0=73.22649470105969, w1=13.556319108818373\n",
      "SubSGD iter. 193/499: loss=16.73000970066042, w0=73.22677464507089, w1=13.556325660503834\n",
      "SubSGD iter. 194/499: loss=16.73004493288224, w0=73.22691461707649, w1=13.556608017528578\n",
      "SubSGD iter. 195/499: loss=16.73000972698743, w0=73.22691461707649, w1=13.556391309633817\n",
      "SubSGD iter. 196/499: loss=16.730059046892084, w0=73.22691461707649, w1=13.556694814440789\n",
      "SubSGD iter. 197/499: loss=16.73000977721641, w0=73.22705458908209, w1=13.5564569587638\n",
      "SubSGD iter. 198/499: loss=16.73002998730957, w0=73.22691461707649, w1=13.55651605620832\n",
      "SubSGD iter. 199/499: loss=16.7299948013435, w0=73.22691461707649, w1=13.556299348313559\n",
      "SubSGD iter. 200/499: loss=16.730044093337455, w0=73.22691461707649, w1=13.55660285312053\n",
      "SubSGD iter. 201/499: loss=16.730008888561812, w0=73.22691461707649, w1=13.556386145225769\n",
      "SubSGD iter. 202/499: loss=16.730058206899045, w0=73.22691461707649, w1=13.556689650032741\n",
      "SubSGD iter. 203/499: loss=16.730022983313823, w0=73.22691461707649, w1=13.55647294213798\n",
      "SubSGD iter. 204/499: loss=16.730043213943727, w0=73.22677464507089, w1=13.5565320395825\n",
      "SubSGD iter. 205/499: loss=16.72999396339281, w0=73.22691461707649, w1=13.55629418390551\n",
      "SubSGD iter. 206/499: loss=16.730043253819343, w0=73.22691461707649, w1=13.556597688712483\n",
      "SubSGD iter. 207/499: loss=16.730008050162866, w0=73.22691461707649, w1=13.556380980817721\n",
      "SubSGD iter. 208/499: loss=16.73005736693268, w0=73.22691461707649, w1=13.556684485624693\n",
      "SubSGD iter. 209/499: loss=16.730022144466624, w0=73.22691461707649, w1=13.556467777729932\n",
      "SubSGD iter. 210/499: loss=16.730042374791324, w0=73.22677464507089, w1=13.556526875174452\n",
      "SubSGD iter. 211/499: loss=16.72999312546879, w0=73.22691461707649, w1=13.556289019497463\n",
      "SubSGD iter. 212/499: loss=16.7300424143279, w0=73.22691461707649, w1=13.556592524304435\n",
      "SubSGD iter. 213/499: loss=16.73000721179059, w0=73.22691461707649, w1=13.556375816409673\n",
      "SubSGD iter. 214/499: loss=16.730056526992982, w0=73.22691461707649, w1=13.556679321216645\n",
      "SubSGD iter. 215/499: loss=16.730021305646094, w0=73.22691461707649, w1=13.556462613321884\n",
      "SubSGD iter. 216/499: loss=16.730041535665592, w0=73.22677464507089, w1=13.556521710766404\n",
      "SubSGD iter. 217/499: loss=16.729992287571438, w0=73.22691461707649, w1=13.556283855089415\n",
      "SubSGD iter. 218/499: loss=16.73004157486313, w0=73.22691461707649, w1=13.556587359896387\n",
      "SubSGD iter. 219/499: loss=16.730006373444986, w0=73.22691461707649, w1=13.556370652001625\n",
      "SubSGD iter. 220/499: loss=16.730055687079957, w0=73.22691461707649, w1=13.556674156808597\n",
      "SubSGD iter. 221/499: loss=16.730020466852235, w0=73.22691461707649, w1=13.556457448913836\n",
      "SubSGD iter. 222/499: loss=16.730040696566533, w0=73.22677464507089, w1=13.556516546358356\n",
      "SubSGD iter. 223/499: loss=16.729991449700766, w0=73.22691461707649, w1=13.556278690681367\n",
      "SubSGD iter. 224/499: loss=16.73004073542503, w0=73.22691461707649, w1=13.556582195488339\n",
      "SubSGD iter. 225/499: loss=16.730005535126054, w0=73.22691461707649, w1=13.556365487593578\n",
      "SubSGD iter. 226/499: loss=16.7300548471936, w0=73.22691461707649, w1=13.55666899240055\n",
      "SubSGD iter. 227/499: loss=16.73001962808505, w0=73.22691461707649, w1=13.556452284505788\n",
      "SubSGD iter. 228/499: loss=16.73003985749414, w0=73.22677464507089, w1=13.556511381950308\n",
      "SubSGD iter. 229/499: loss=16.72999061185676, w0=73.22691461707649, w1=13.55627352627332\n",
      "SubSGD iter. 230/499: loss=16.730039896013597, w0=73.22691461707649, w1=13.556577031080291\n",
      "SubSGD iter. 231/499: loss=16.730004696833795, w0=73.22691461707649, w1=13.55636032318553\n",
      "SubSGD iter. 232/499: loss=16.730054007333916, w0=73.22691461707649, w1=13.556663827992502\n",
      "SubSGD iter. 233/499: loss=16.730018789344534, w0=73.22691461707649, w1=13.55644712009774\n",
      "SubSGD iter. 234/499: loss=16.730039018448423, w0=73.22677464507089, w1=13.55650621754226\n",
      "SubSGD iter. 235/499: loss=16.72998977403942, w0=73.22691461707649, w1=13.556268361865271\n",
      "SubSGD iter. 236/499: loss=16.730039056628843, w0=73.22691461707649, w1=13.556571866672243\n",
      "SubSGD iter. 237/499: loss=16.730003858568203, w0=73.22691461707649, w1=13.556355158777482\n",
      "SubSGD iter. 238/499: loss=16.7300531675009, w0=73.22691461707649, w1=13.556658663584454\n",
      "SubSGD iter. 239/499: loss=16.73001795063069, w0=73.22691461707649, w1=13.556441955689692\n",
      "SubSGD iter. 240/499: loss=16.730038179429375, w0=73.22677464507089, w1=13.556501053134212\n",
      "SubSGD iter. 241/499: loss=16.730018004184537, w0=73.22705458908209, w1=13.556507604819673\n",
      "SubSGD iter. 242/499: loss=16.730038217270756, w0=73.22691461707649, w1=13.556566702264194\n",
      "SubSGD iter. 243/499: loss=16.730003020329285, w0=73.22691461707649, w1=13.556349994369432\n",
      "SubSGD iter. 244/499: loss=16.730052327694562, w0=73.22691461707649, w1=13.556653499176404\n",
      "SubSGD iter. 245/499: loss=16.730017111943514, w0=73.22691461707649, w1=13.556436791281643\n",
      "SubSGD iter. 246/499: loss=16.730037340436997, w0=73.22677464507089, w1=13.556495888726163\n",
      "SubSGD iter. 247/499: loss=16.730017165158323, w0=73.22705458908209, w1=13.556502440411624\n",
      "SubSGD iter. 248/499: loss=16.73003737793934, w0=73.22691461707649, w1=13.556561537856144\n",
      "SubSGD iter. 249/499: loss=16.730002182117037, w0=73.22691461707649, w1=13.556344829961382\n",
      "SubSGD iter. 250/499: loss=16.73005148791489, w0=73.22691461707649, w1=13.556648334768354\n",
      "SubSGD iter. 251/499: loss=16.73001627328301, w0=73.22691461707649, w1=13.556431626873593\n",
      "SubSGD iter. 252/499: loss=16.73003650147129, w0=73.22677464507089, w1=13.556490724318113\n",
      "SubSGD iter. 253/499: loss=16.73001632615878, w0=73.22705458908209, w1=13.556497276003574\n",
      "SubSGD iter. 254/499: loss=16.730036538634593, w0=73.22691461707649, w1=13.556556373448094\n",
      "SubSGD iter. 255/499: loss=16.73000134393146, w0=73.22691461707649, w1=13.556339665553333\n",
      "SubSGD iter. 256/499: loss=16.73005064816189, w0=73.22691461707649, w1=13.556643170360305\n",
      "SubSGD iter. 257/499: loss=16.730015434649182, w0=73.22691461707649, w1=13.556426462465543\n",
      "SubSGD iter. 258/499: loss=16.730035662532256, w0=73.22677464507089, w1=13.556485559910064\n",
      "SubSGD iter. 259/499: loss=16.73001548718591, w0=73.22705458908209, w1=13.556492111595524\n",
      "SubSGD iter. 260/499: loss=16.73003569935652, w0=73.22691461707649, w1=13.556551209040045\n",
      "SubSGD iter. 261/499: loss=16.730000505772555, w0=73.22691461707649, w1=13.556334501145283\n",
      "SubSGD iter. 262/499: loss=16.730049808435563, w0=73.22691461707649, w1=13.556638005952255\n",
      "SubSGD iter. 263/499: loss=16.730014596042018, w0=73.22691461707649, w1=13.556421298057494\n",
      "SubSGD iter. 264/499: loss=16.73006392504831, w0=73.22691461707649, w1=13.556724802864466\n",
      "SubSGD iter. 265/499: loss=16.73001464823971, w0=73.22705458908209, w1=13.556486947187476\n",
      "SubSGD iter. 266/499: loss=16.730034860105114, w0=73.22691461707649, w1=13.556546044631997\n",
      "SubSGD iter. 267/499: loss=16.729999667640318, w0=73.22691461707649, w1=13.556329336737235\n",
      "SubSGD iter. 268/499: loss=16.730048968735904, w0=73.22691461707649, w1=13.556632841544207\n",
      "SubSGD iter. 269/499: loss=16.730013757461528, w0=73.22691461707649, w1=13.556416133649446\n",
      "SubSGD iter. 270/499: loss=16.730063084900394, w0=73.22691461707649, w1=13.556719638456418\n",
      "SubSGD iter. 271/499: loss=16.730013809320184, w0=73.22705458908209, w1=13.556481782779429\n",
      "SubSGD iter. 272/499: loss=16.730034020880385, w0=73.22691461707649, w1=13.556540880223949\n",
      "SubSGD iter. 273/499: loss=16.729998829534757, w0=73.22691461707649, w1=13.556324172329187\n",
      "SubSGD iter. 274/499: loss=16.73004812906292, w0=73.22691461707649, w1=13.55662767713616\n",
      "SubSGD iter. 275/499: loss=16.73001291890771, w0=73.22691461707649, w1=13.556410969241398\n",
      "SubSGD iter. 276/499: loss=16.730062244779155, w0=73.22691461707649, w1=13.55671447404837\n",
      "SubSGD iter. 277/499: loss=16.730012970427325, w0=73.22705458908209, w1=13.55647661837138\n",
      "SubSGD iter. 278/499: loss=16.730033181682323, w0=73.22691461707649, w1=13.556535715815901\n",
      "SubSGD iter. 279/499: loss=16.729997991455864, w0=73.22691461707649, w1=13.55631900792114\n",
      "SubSGD iter. 280/499: loss=16.730047289416603, w0=73.22691461707649, w1=13.556622512728111\n",
      "SubSGD iter. 281/499: loss=16.730012080380565, w0=73.22691461707649, w1=13.55640580483335\n",
      "SubSGD iter. 282/499: loss=16.730061404684584, w0=73.22691461707649, w1=13.556709309640322\n",
      "SubSGD iter. 283/499: loss=16.73001213156114, w0=73.22705458908209, w1=13.556471453963333\n",
      "SubSGD iter. 284/499: loss=16.730032342510935, w0=73.22691461707649, w1=13.556530551407853\n",
      "SubSGD iter. 285/499: loss=16.72999715340364, w0=73.22691461707649, w1=13.556313843513092\n",
      "SubSGD iter. 286/499: loss=16.73004644979696, w0=73.22691461707649, w1=13.556617348320064\n",
      "SubSGD iter. 287/499: loss=16.73001124188009, w0=73.22691461707649, w1=13.556400640425302\n",
      "SubSGD iter. 288/499: loss=16.730060564616686, w0=73.22691461707649, w1=13.556704145232274\n",
      "SubSGD iter. 289/499: loss=16.730011292721624, w0=73.22705458908209, w1=13.556466289555285\n",
      "SubSGD iter. 290/499: loss=16.73003150336622, w0=73.22691461707649, w1=13.556525386999805\n",
      "SubSGD iter. 291/499: loss=16.72999631537809, w0=73.22691461707649, w1=13.556308679105044\n",
      "SubSGD iter. 292/499: loss=16.730045610203987, w0=73.22691461707649, w1=13.556612183912016\n",
      "SubSGD iter. 293/499: loss=16.730010403406283, w0=73.22691461707649, w1=13.556395476017254\n",
      "SubSGD iter. 294/499: loss=16.73005972457546, w0=73.22691461707649, w1=13.556698980824226\n",
      "SubSGD iter. 295/499: loss=16.73001045390878, w0=73.22705458908209, w1=13.556461125147237\n",
      "SubSGD iter. 296/499: loss=16.73003066424817, w0=73.22691461707649, w1=13.556520222591757\n",
      "SubSGD iter. 297/499: loss=16.729995477379212, w0=73.22691461707649, w1=13.556303514696996\n",
      "SubSGD iter. 298/499: loss=16.730044770637683, w0=73.22691461707649, w1=13.556607019503968\n",
      "SubSGD iter. 299/499: loss=16.730009564959154, w0=73.22691461707649, w1=13.556390311609206\n",
      "SubSGD iter. 300/499: loss=16.7300588845609, w0=73.22691461707649, w1=13.556693816416178\n",
      "SubSGD iter. 301/499: loss=16.73000961512261, w0=73.22705458908209, w1=13.55645596073919\n",
      "SubSGD iter. 302/499: loss=16.73002982515679, w0=73.22691461707649, w1=13.55651505818371\n",
      "SubSGD iter. 303/499: loss=16.729994639407003, w0=73.22691461707649, w1=13.556298350288948\n",
      "SubSGD iter. 304/499: loss=16.730043931098056, w0=73.22691461707649, w1=13.55660185509592\n",
      "SubSGD iter. 305/499: loss=16.73000872653869, w0=73.22691461707649, w1=13.556385147201159\n",
      "SubSGD iter. 306/499: loss=16.730058044573017, w0=73.22691461707649, w1=13.55668865200813\n",
      "SubSGD iter. 307/499: loss=16.730022821204077, w0=73.22691461707649, w1=13.556471944113369\n",
      "SubSGD iter. 308/499: loss=16.730043051775002, w0=73.22677464507089, w1=13.55653104155789\n",
      "SubSGD iter. 309/499: loss=16.729993801461468, w0=73.22691461707649, w1=13.5562931858809\n",
      "SubSGD iter. 310/499: loss=16.730043091585095, w0=73.22691461707649, w1=13.556596690687872\n",
      "SubSGD iter. 311/499: loss=16.7300078881449, w0=73.22691461707649, w1=13.55637998279311\n",
      "SubSGD iter. 312/499: loss=16.730057204611803, w0=73.22691461707649, w1=13.556683487600083\n",
      "SubSGD iter. 313/499: loss=16.73002198236203, w0=73.22691461707649, w1=13.556466779705321\n",
      "SubSGD iter. 314/499: loss=16.73004221262775, w0=73.22677464507089, w1=13.556525877149841\n",
      "SubSGD iter. 315/499: loss=16.7299929635426, w0=73.22691461707649, w1=13.556288021472852\n",
      "SubSGD iter. 316/499: loss=16.730042252098805, w0=73.22691461707649, w1=13.556591526279824\n",
      "SubSGD iter. 317/499: loss=16.730007049777775, w0=73.22691461707649, w1=13.556374818385063\n",
      "SubSGD iter. 318/499: loss=16.73005636467726, w0=73.22691461707649, w1=13.556678323192035\n",
      "SubSGD iter. 319/499: loss=16.730021143546654, w0=73.22691461707649, w1=13.556461615297273\n",
      "SubSGD iter. 320/499: loss=16.730041373507174, w0=73.22677464507089, w1=13.556520712741793\n",
      "SubSGD iter. 321/499: loss=16.72999212565041, w0=73.22691461707649, w1=13.556282857064804\n",
      "SubSGD iter. 322/499: loss=16.730041412639185, w0=73.22691461707649, w1=13.556586361871776\n",
      "SubSGD iter. 323/499: loss=16.730006211437324, w0=73.22691461707649, w1=13.556369653977015\n",
      "SubSGD iter. 324/499: loss=16.73005552476939, w0=73.22691461707649, w1=13.556673158783987\n",
      "SubSGD iter. 325/499: loss=16.73002030475795, w0=73.22691461707649, w1=13.556456450889225\n",
      "SubSGD iter. 326/499: loss=16.730040534413266, w0=73.22677464507089, w1=13.556515548333746\n",
      "SubSGD iter. 327/499: loss=16.729991287784884, w0=73.22691461707649, w1=13.556277692656757\n",
      "SubSGD iter. 328/499: loss=16.730040573206246, w0=73.22691461707649, w1=13.556581197463728\n",
      "SubSGD iter. 329/499: loss=16.73000537312355, w0=73.22691461707649, w1=13.556364489568967\n",
      "SubSGD iter. 330/499: loss=16.730054684888188, w0=73.22691461707649, w1=13.556667994375939\n",
      "SubSGD iter. 331/499: loss=16.73001946599592, w0=73.22691461707649, w1=13.556451286481177\n",
      "SubSGD iter. 332/499: loss=16.730039695346026, w0=73.22677464507089, w1=13.556510383925698\n",
      "SubSGD iter. 333/499: loss=16.729990449946033, w0=73.22691461707649, w1=13.556272528248709\n",
      "SubSGD iter. 334/499: loss=16.73003973379997, w0=73.22691461707649, w1=13.55657603305568\n",
      "SubSGD iter. 335/499: loss=16.730004534836443, w0=73.22691461707649, w1=13.55635932516092\n",
      "SubSGD iter. 336/499: loss=16.73005384503366, w0=73.22691461707649, w1=13.556662829967891\n",
      "SubSGD iter. 337/499: loss=16.730018627260556, w0=73.22691461707649, w1=13.55644612207313\n",
      "SubSGD iter. 338/499: loss=16.730038856305463, w0=73.22677464507089, w1=13.55650521951765\n",
      "SubSGD iter. 339/499: loss=16.72998961213385, w0=73.22691461707649, w1=13.55626736384066\n",
      "SubSGD iter. 340/499: loss=16.730038894420364, w0=73.22691461707649, w1=13.556570868647633\n",
      "SubSGD iter. 341/499: loss=16.73000369657601, w0=73.22691461707649, w1=13.556354160752871\n",
      "SubSGD iter. 342/499: loss=16.7300530052058, w0=73.22691461707649, w1=13.556657665559843\n",
      "SubSGD iter. 343/499: loss=16.730017788551866, w0=73.22691461707649, w1=13.556440957665082\n",
      "SubSGD iter. 344/499: loss=16.73003801729157, w0=73.22677464507089, w1=13.556500055109602\n",
      "SubSGD iter. 345/499: loss=16.730017842040194, w0=73.22705458908209, w1=13.556506606795063\n",
      "SubSGD iter. 346/499: loss=16.730038055067432, w0=73.22691461707649, w1=13.556565704239583\n",
      "SubSGD iter. 347/499: loss=16.730002858342242, w0=73.22691461707649, w1=13.556348996344822\n",
      "SubSGD iter. 348/499: loss=16.73005216540461, w0=73.22691461707649, w1=13.556652501151794\n",
      "SubSGD iter. 349/499: loss=16.730016949869846, w0=73.22691461707649, w1=13.556435793257032\n",
      "SubSGD iter. 350/499: loss=16.730037178304347, w0=73.22677464507089, w1=13.556494890701552\n",
      "SubSGD iter. 351/499: loss=16.730017003019135, w0=73.22705458908209, w1=13.556501442387013\n",
      "SubSGD iter. 352/499: loss=16.73003721574117, w0=73.22691461707649, w1=13.556560539831533\n",
      "SubSGD iter. 353/499: loss=16.730002020135142, w0=73.22691461707649, w1=13.556343831936772\n",
      "SubSGD iter. 354/499: loss=16.730051325630093, w0=73.22691461707649, w1=13.556647336743744\n",
      "SubSGD iter. 355/499: loss=16.7300161112145, w0=73.22691461707649, w1=13.556430628848982\n",
      "SubSGD iter. 356/499: loss=16.730036339343798, w0=73.22677464507089, w1=13.556489726293503\n",
      "SubSGD iter. 357/499: loss=16.73001616402475, w0=73.22705458908209, w1=13.556496277978964\n",
      "SubSGD iter. 358/499: loss=16.730036376441582, w0=73.22691461707649, w1=13.556555375423484\n",
      "SubSGD iter. 359/499: loss=16.730001181954723, w0=73.22691461707649, w1=13.556338667528722\n",
      "SubSGD iter. 360/499: loss=16.73005048588225, w0=73.22691461707649, w1=13.556642172335694\n",
      "SubSGD iter. 361/499: loss=16.73001527258582, w0=73.22691461707649, w1=13.556425464440933\n",
      "SubSGD iter. 362/499: loss=16.730035500409915, w0=73.22677464507089, w1=13.556484561885453\n",
      "SubSGD iter. 363/499: loss=16.730015325057032, w0=73.22705458908209, w1=13.556491113570914\n",
      "SubSGD iter. 364/499: loss=16.73003553716866, w0=73.22691461707649, w1=13.556550211015434\n",
      "SubSGD iter. 365/499: loss=16.730000343800974, w0=73.22691461707649, w1=13.556333503120673\n",
      "SubSGD iter. 366/499: loss=16.730049646161078, w0=73.22691461707649, w1=13.556637007927645\n",
      "SubSGD iter. 367/499: loss=16.730014433983815, w0=73.22691461707649, w1=13.556420300032883\n",
      "SubSGD iter. 368/499: loss=16.730063762687198, w0=73.22691461707649, w1=13.556723804839855\n",
      "SubSGD iter. 369/499: loss=16.730014486115987, w0=73.22705458908209, w1=13.556485949162866\n",
      "SubSGD iter. 370/499: loss=16.730034697922413, w0=73.22691461707649, w1=13.556545046607386\n",
      "SubSGD iter. 371/499: loss=16.72999950567389, w0=73.22691461707649, w1=13.556328338712625\n",
      "SubSGD iter. 372/499: loss=16.730048806466574, w0=73.22691461707649, w1=13.556631843519597\n",
      "SubSGD iter. 373/499: loss=16.73001359540848, w0=73.22691461707649, w1=13.556415135624835\n",
      "SubSGD iter. 374/499: loss=16.730062922544437, w0=73.22691461707649, w1=13.556718640431807\n",
      "SubSGD iter. 375/499: loss=16.730013647201613, w0=73.22705458908209, w1=13.556480784754818\n",
      "SubSGD iter. 376/499: loss=16.730033858702832, w0=73.22691461707649, w1=13.556539882199338\n",
      "SubSGD iter. 377/499: loss=16.729998667573483, w0=73.22691461707649, w1=13.556323174304577\n",
      "SubSGD iter. 378/499: loss=16.73004796679874, w0=73.22691461707649, w1=13.556626679111549\n",
      "SubSGD iter. 379/499: loss=16.730012756859818, w0=73.22691461707649, w1=13.556409971216787\n",
      "SubSGD iter. 380/499: loss=16.730062082428354, w0=73.22691461707649, w1=13.55671347602376\n",
      "SubSGD iter. 381/499: loss=16.73001280831391, w0=73.22705458908209, w1=13.55647562034677\n",
      "SubSGD iter. 382/499: loss=16.73003301950993, w0=73.22691461707649, w1=13.55653471779129\n",
      "SubSGD iter. 383/499: loss=16.729997829499744, w0=73.22691461707649, w1=13.556318009896529\n",
      "SubSGD iter. 384/499: loss=16.73004712715758, w0=73.22691461707649, w1=13.556621514703501\n",
      "SubSGD iter. 385/499: loss=16.73001191833782, w0=73.22691461707649, w1=13.55640480680874\n",
      "SubSGD iter. 386/499: loss=16.730061242338937, w0=73.22691461707649, w1=13.556708311615711\n",
      "SubSGD iter. 387/499: loss=16.730011969452878, w0=73.22705458908209, w1=13.556470455938722\n",
      "SubSGD iter. 388/499: loss=16.73003218034369, w0=73.22691461707649, w1=13.556529553383243\n",
      "SubSGD iter. 389/499: loss=16.72999699145268, w0=73.22691461707649, w1=13.556312845488481\n",
      "SubSGD iter. 390/499: loss=16.73004628754309, w0=73.22691461707649, w1=13.556616350295453\n",
      "SubSGD iter. 391/499: loss=16.7300110798425, w0=73.22691461707649, w1=13.556399642400692\n",
      "SubSGD iter. 392/499: loss=16.73006040227619, w0=73.22691461707649, w1=13.556703147207664\n",
      "SubSGD iter. 393/499: loss=16.730011130618518, w0=73.22705458908209, w1=13.556465291530674\n",
      "SubSGD iter. 394/499: loss=16.730031341204132, w0=73.22691461707649, w1=13.556524388975195\n",
      "SubSGD iter. 395/499: loss=16.729996153432282, w0=73.22691461707649, w1=13.556307681080433\n",
      "SubSGD iter. 396/499: loss=16.730045447955273, w0=73.22691461707649, w1=13.556611185887405\n",
      "SubSGD iter. 397/499: loss=16.730010241373847, w0=73.22691461707649, w1=13.556394477992644\n",
      "SubSGD iter. 398/499: loss=16.73005956224012, w0=73.22691461707649, w1=13.556697982799616\n",
      "SubSGD iter. 399/499: loss=16.730010291810828, w0=73.22705458908209, w1=13.556460127122627\n",
      "SubSGD iter. 400/499: loss=16.730030502091235, w0=73.22691461707649, w1=13.556519224567147\n",
      "SubSGD iter. 401/499: loss=16.729995315438558, w0=73.22691461707649, w1=13.556302516672385\n",
      "SubSGD iter. 402/499: loss=16.730044608394124, w0=73.22691461707649, w1=13.556606021479357\n",
      "SubSGD iter. 403/499: loss=16.730009402931874, w0=73.22691461707649, w1=13.556389313584596\n",
      "SubSGD iter. 404/499: loss=16.730058722230716, w0=73.22691461707649, w1=13.556692818391568\n",
      "SubSGD iter. 405/499: loss=16.73000945302981, w0=73.22705458908209, w1=13.556454962714579\n",
      "SubSGD iter. 406/499: loss=16.730029663005013, w0=73.22691461707649, w1=13.556514060159099\n",
      "SubSGD iter. 407/499: loss=16.729994477471504, w0=73.22691461707649, w1=13.556297352264338\n",
      "SubSGD iter. 408/499: loss=16.73004376885965, w0=73.22691461707649, w1=13.55660085707131\n",
      "SubSGD iter. 409/499: loss=16.730008564516563, w0=73.22691461707649, w1=13.556384149176548\n",
      "SubSGD iter. 410/499: loss=16.730057882247984, w0=73.22691461707649, w1=13.55668765398352\n",
      "SubSGD iter. 411/499: loss=16.730022659095322, w0=73.22691461707649, w1=13.556470946088758\n",
      "SubSGD iter. 412/499: loss=16.730042889607265, w0=73.22677464507089, w1=13.556530043533279\n",
      "SubSGD iter. 413/499: loss=16.72999363953112, w0=73.22691461707649, w1=13.55629218785629\n",
      "SubSGD iter. 414/499: loss=16.730042929351843, w0=73.22691461707649, w1=13.556595692663262\n",
      "SubSGD iter. 415/499: loss=16.730007726127923, w0=73.22691461707649, w1=13.5563789847685\n",
      "SubSGD iter. 416/499: loss=16.730057042291925, w0=73.22691461707649, w1=13.556682489575472\n",
      "SubSGD iter. 417/499: loss=16.73002182025843, w0=73.22691461707649, w1=13.55646578168071\n",
      "SubSGD iter. 418/499: loss=16.73004205046517, w0=73.22677464507089, w1=13.55652487912523\n",
      "SubSGD iter. 419/499: loss=16.72999280161741, w0=73.22691461707649, w1=13.556287023448242\n",
      "SubSGD iter. 420/499: loss=16.730042089870707, w0=73.22691461707649, w1=13.556590528255214\n",
      "SubSGD iter. 421/499: loss=16.73000688776596, w0=73.22691461707649, w1=13.556373820360452\n",
      "SubSGD iter. 422/499: loss=16.730056202362537, w0=73.22691461707649, w1=13.556677325167424\n",
      "SubSGD iter. 423/499: loss=16.730020981448213, w0=73.22691461707649, w1=13.556460617272663\n",
      "SubSGD iter. 424/499: loss=16.730041211349747, w0=73.22677464507089, w1=13.556519714717183\n",
      "SubSGD iter. 425/499: loss=16.729991963730367, w0=73.22691461707649, w1=13.556281859040194\n",
      "SubSGD iter. 426/499: loss=16.730041250416246, w0=73.22691461707649, w1=13.556585363847166\n",
      "SubSGD iter. 427/499: loss=16.730006049430663, w0=73.22691461707649, w1=13.556368655952404\n",
      "SubSGD iter. 428/499: loss=16.730055362459822, w0=73.22691461707649, w1=13.556672160759376\n",
      "SubSGD iter. 429/499: loss=16.73002014266466, w0=73.22691461707649, w1=13.556455452864615\n",
      "SubSGD iter. 430/499: loss=16.73004037226099, w0=73.22677464507089, w1=13.556514550309135\n",
      "SubSGD iter. 431/499: loss=16.72999112587, w0=73.22691461707649, w1=13.556276694632146\n",
      "SubSGD iter. 432/499: loss=16.73004041098845, w0=73.22691461707649, w1=13.556580199439118\n",
      "SubSGD iter. 433/499: loss=16.730005211122037, w0=73.22691461707649, w1=13.556363491544356\n",
      "SubSGD iter. 434/499: loss=16.730054522583774, w0=73.22691461707649, w1=13.556666996351328\n",
      "SubSGD iter. 435/499: loss=16.73001930390778, w0=73.22691461707649, w1=13.556450288456567\n",
      "SubSGD iter. 436/499: loss=16.730039533198912, w0=73.22677464507089, w1=13.556509385901087\n",
      "SubSGD iter. 437/499: loss=16.729990288036298, w0=73.22691461707649, w1=13.556271530224098\n",
      "SubSGD iter. 438/499: loss=16.730039571587334, w0=73.22691461707649, w1=13.55657503503107\n",
      "SubSGD iter. 439/499: loss=16.73000437284009, w0=73.22691461707649, w1=13.556358327136309\n",
      "SubSGD iter. 440/499: loss=16.730053682734397, w0=73.22691461707649, w1=13.55666183194328\n",
      "SubSGD iter. 441/499: loss=16.730018465177572, w0=73.22691461707649, w1=13.556445124048519\n",
      "SubSGD iter. 442/499: loss=16.730038694163504, w0=73.22677464507089, w1=13.55650422149304\n",
      "SubSGD iter. 443/499: loss=16.73001851893942, w0=73.22705458908209, w1=13.5565107731785\n",
      "SubSGD iter. 444/499: loss=16.730038732212883, w0=73.22691461707649, w1=13.55656987062302\n",
      "SubSGD iter. 445/499: loss=16.730003534584807, w0=73.22691461707649, w1=13.556353162728259\n",
      "SubSGD iter. 446/499: loss=16.730052842911693, w0=73.22691461707649, w1=13.556656667535231\n",
      "SubSGD iter. 447/499: loss=16.73001762647404, w0=73.22691461707649, w1=13.55643995964047\n",
      "SubSGD iter. 448/499: loss=16.73003785515476, w0=73.22677464507089, w1=13.55649905708499\n",
      "SubSGD iter. 449/499: loss=16.730017679896847, w0=73.22705458908209, w1=13.55650560877045\n",
      "SubSGD iter. 450/499: loss=16.730037892865106, w0=73.22691461707649, w1=13.55656470621497\n",
      "SubSGD iter. 451/499: loss=16.730002696356195, w0=73.22691461707649, w1=13.55634799832021\n",
      "SubSGD iter. 452/499: loss=16.73005200311566, w0=73.22691461707649, w1=13.556651503127181\n",
      "SubSGD iter. 453/499: loss=16.730016787797172, w0=73.22691461707649, w1=13.55643479523242\n",
      "SubSGD iter. 454/499: loss=16.73003701617269, w0=73.22677464507089, w1=13.55649389267694\n",
      "SubSGD iter. 455/499: loss=16.730016840880943, w0=73.22705458908209, w1=13.5565004443624\n",
      "SubSGD iter. 456/499: loss=16.730037053544, w0=73.22691461707649, w1=13.556559541806921\n",
      "SubSGD iter. 457/499: loss=16.730001858154253, w0=73.22691461707649, w1=13.55634283391216\n",
      "SubSGD iter. 458/499: loss=16.7300511633463, w0=73.22691461707649, w1=13.556646338719132\n",
      "SubSGD iter. 459/499: loss=16.730015949146978, w0=73.22691461707649, w1=13.55642963082437\n",
      "SubSGD iter. 460/499: loss=16.730036177217293, w0=73.22677464507089, w1=13.55648872826889\n",
      "SubSGD iter. 461/499: loss=16.73001600189171, w0=73.22705458908209, w1=13.556495279954351\n",
      "SubSGD iter. 462/499: loss=16.73003621424956, w0=73.22691461707649, w1=13.556554377398871\n",
      "SubSGD iter. 463/499: loss=16.730001019978985, w0=73.22691461707649, w1=13.55633766950411\n",
      "SubSGD iter. 464/499: loss=16.730050323603606, w0=73.22691461707649, w1=13.556641174311082\n",
      "SubSGD iter. 465/499: loss=16.730015110523457, w0=73.22691461707649, w1=13.55642446641632\n",
      "SubSGD iter. 466/499: loss=16.730064440491354, w0=73.22691461707649, w1=13.556727971223292\n",
      "SubSGD iter. 467/499: loss=16.73001516292915, w0=73.22705458908209, w1=13.556490115546303\n",
      "SubSGD iter. 468/499: loss=16.730035374981796, w0=73.22691461707649, w1=13.556549212990824\n",
      "SubSGD iter. 469/499: loss=16.730000181830388, w0=73.22691461707649, w1=13.556332505096062\n",
      "SubSGD iter. 470/499: loss=16.730049483887584, w0=73.22691461707649, w1=13.556636009903034\n",
      "SubSGD iter. 471/499: loss=16.730014271926606, w0=73.22691461707649, w1=13.556419302008273\n",
      "SubSGD iter. 472/499: loss=16.73006360032708, w0=73.22691461707649, w1=13.556722806815245\n",
      "SubSGD iter. 473/499: loss=16.73001432399326, w0=73.22705458908209, w1=13.556484951138255\n",
      "SubSGD iter. 474/499: loss=16.730034535740703, w0=73.22691461707649, w1=13.556544048582776\n",
      "SubSGD iter. 475/499: loss=16.729999343708464, w0=73.22691461707649, w1=13.556327340688014\n",
      "SubSGD iter. 476/499: loss=16.730048644198234, w0=73.22691461707649, w1=13.556630845494986\n",
      "SubSGD iter. 477/499: loss=16.730013433356426, w0=73.22691461707649, w1=13.556414137600225\n",
      "SubSGD iter. 478/499: loss=16.730062760189476, w0=73.22691461707649, w1=13.556717642407197\n",
      "SubSGD iter. 479/499: loss=16.730013485084037, w0=73.22705458908209, w1=13.556479786730208\n",
      "SubSGD iter. 480/499: loss=16.730033696526277, w0=73.22691461707649, w1=13.556538884174728\n",
      "SubSGD iter. 481/499: loss=16.72999850561321, w0=73.22691461707649, w1=13.556322176279966\n",
      "SubSGD iter. 482/499: loss=16.73004780453556, w0=73.22691461707649, w1=13.556625681086938\n",
      "SubSGD iter. 483/499: loss=16.730012594812912, w0=73.22691461707649, w1=13.556408973192177\n",
      "SubSGD iter. 484/499: loss=16.730061920078544, w0=73.22691461707649, w1=13.556712477999149\n",
      "SubSGD iter. 485/499: loss=16.730012646201487, w0=73.22705458908209, w1=13.55647462232216\n",
      "SubSGD iter. 486/499: loss=16.73003285733853, w0=73.22691461707649, w1=13.55653371976668\n",
      "SubSGD iter. 487/499: loss=16.729997667544627, w0=73.22691461707649, w1=13.556317011871919\n",
      "SubSGD iter. 488/499: loss=16.730046964899554, w0=73.22691461707649, w1=13.55662051667889\n",
      "SubSGD iter. 489/499: loss=16.730011756296072, w0=73.22691461707649, w1=13.556403808784129\n",
      "SubSGD iter. 490/499: loss=16.730061079994286, w0=73.22691461707649, w1=13.556707313591101\n",
      "SubSGD iter. 491/499: loss=16.730011807345612, w0=73.22705458908209, w1=13.556469457914112\n",
      "SubSGD iter. 492/499: loss=16.730032018177447, w0=73.22691461707649, w1=13.556528555358632\n",
      "SubSGD iter. 493/499: loss=16.72999682950271, w0=73.22691461707649, w1=13.55631184746387\n",
      "SubSGD iter. 494/499: loss=16.730046125290215, w0=73.22691461707649, w1=13.556615352270843\n",
      "SubSGD iter. 495/499: loss=16.730010917805906, w0=73.22691461707649, w1=13.556398644376081\n",
      "SubSGD iter. 496/499: loss=16.730060239936694, w0=73.22691461707649, w1=13.556702149183053\n",
      "SubSGD iter. 497/499: loss=16.730010968516403, w0=73.22705458908209, w1=13.556464293506064\n",
      "SubSGD iter. 498/499: loss=16.730031179043035, w0=73.22691461707649, w1=13.556523390950584\n",
      "SubSGD iter. 499/499: loss=16.729995991487467, w0=73.22691461707649, w1=13.556306683055823\n",
      "SubSGD: execution time=9.048 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2c124849454f68851a1d090552397b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses,\n",
    "        subsgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
